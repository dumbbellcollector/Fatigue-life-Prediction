import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import joblib
import os
import pandas as pd
import io # For image download

# --- File Paths (Global Constants) ---
# Attempt to determine script directory for robust pathing
try:
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
except NameError: # Occurs when running in some environments like notebooks directly
    BASE_DIR = os.getcwd()

MODEL_PATH = os.path.join(BASE_DIR, 'best_fatigue_pinn_model.pth')
SCALER_X_PATH = os.path.join(BASE_DIR, 'scaler_X.pkl')
SCALER_Y_PATH = os.path.join(BASE_DIR, 'scalers_y.pkl')

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
print(f"Streamlit App: Using device: {device}")

# --- Input Validation Function ---
def all_inputs_valid(e_mod, ys, ts, hb_input, poisson_ratio):
    if e_mod is None or e_mod <= 0: return False
    if ys is None or ys <= 0: return False
    if ts is None or ts <= 0: return False
    # HB can be 0 or None if not used for physics, but for prediction it's better to have a value.
    # The predict_fatigue_curves_hybrid handles HB_val being None/nan, so direct check here might be optional
    # depending on strictness. For now, let's assume it should be non-negative if provided.
    if hb_input is not None and hb_input < 0: return False # Allow 0, but not negative
    if poisson_ratio is None or not (0 <= poisson_ratio <= 0.5): return False
    return True

# --- main.ipynbì˜ inverse_transform_targets í•¨ìˆ˜ ---
def inverse_transform_targets(y_scaled_data, scalers_y_dict, target_cols_list):
    if y_scaled_data.ndim == 1:
        y_scaled_data = y_scaled_data.reshape(1, -1)
        
    y_transformed_individually = np.zeros_like(y_scaled_data)
    for i, col_name in enumerate(target_cols_list):
        if col_name not in scalers_y_dict: # í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            raise KeyError(f"Scaler for target '{col_name}' not found in scalers_y_dict. Available keys: {list(scalers_y_dict.keys())}")
        y_transformed_individually[:, i] = scalers_y_dict[col_name].inverse_transform(y_scaled_data[:, i].reshape(-1, 1)).flatten()
    
    y_orig_scale = y_transformed_individually.copy()
    
    # Cell 6ì˜ ê¸°ì¤€ì— ë”°ë¼, ë¡œê·¸ ë³€í™˜ëœ ì»¬ëŸ¼ ì´ë¦„ì€ 'epf'ë¡œ ê°€ì •í•©ë‹ˆë‹¤.
    log_col_expected_name = 'epf' 
    fallback_log_col_name = 'epf_log' # í˜¹ì‹œ 'epf_log'ë¡œ ì €ì¥ëœ pklì„ ìœ„í•œ ëŒ€ì²´ ê²½ë¡œ

    if log_col_expected_name in target_cols_list:
        try:
            current_log_col_idx = target_cols_list.index(log_col_expected_name)
            y_orig_scale[:, current_log_col_idx] = np.expm1(y_transformed_individually[:, current_log_col_idx])
        except ValueError:
            st.warning(f"'{log_col_expected_name}' was in target_cols_list but index could not be found. Skipping expm1 transformation for it.")
    elif fallback_log_col_name in target_cols_list: # 'epf'ê°€ ì—†ê³  'epf_log'ê°€ ìˆëŠ” ê²½ìš°
        try:
            current_fallback_log_col_idx = target_cols_list.index(fallback_log_col_name)
            st.info(f"Note: Found '{fallback_log_col_name}' in target_cols and applying expm1. "
                    f"The primary expected log-column name (based on notebook Cell 6 assumption) is '{log_col_expected_name}'.")
            y_orig_scale[:, current_fallback_log_col_idx] = np.expm1(y_transformed_individually[:, current_fallback_log_col_idx])
        except ValueError:
            st.warning(f"'{fallback_log_col_name}' was in target_cols_list but index could not be found. Skipping expm1 transformation for it.")
            
    if y_scaled_data.shape[0] == 1 and y_orig_scale.shape[0] == 1:
         return y_orig_scale.flatten()
    return y_orig_scale

# --- ëª¨ë¸ ì •ì˜ ë³µì œ (FatiguePINN) ---
class FatiguePINN(nn.Module):
    def __init__(self, input_dim, output_dim, hidden_dims=[128, 256, 128], dropout_p=0.1):
        super().__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.dropout_p = dropout_p # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ì €ì¥

        layers = []
        last_dim = input_dim
        for i, hidden_dim in enumerate(hidden_dims):
            layers.append(nn.Linear(last_dim, hidden_dim))
            layers.append(nn.ReLU())
            # ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ ì¶”ê°€
            if self.dropout_p > 0:
                layers.append(nn.Dropout(p=self.dropout_p))
            last_dim = hidden_dim
        
        layers.append(nn.Linear(last_dim, output_dim))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

# --- Empirical Method Functions ---
HB_CLASS1_MAX = 150; HB_CLASS2_MAX = 500; HB_CLASS3_MAX = 700

def modified_universal_slopes(ts_mpa, e_mpa):
    """Modified Universal Slopes Method"""
    spf = 1.9 * ts_mpa
    epf = 0.623 * (ts_mpa / e_mpa) ** 0.832
    return spf, epf

def uniform_material_law(ts_mpa, e_mpa):
    """Uniform Material Law"""
    if ts_mpa < 750:  # Low strength steel
        spf = 1.5 * ts_mpa
        epf = 0.59 * (ts_mpa / e_mpa) ** 0.58
    else:  # High strength steel
        spf = 1.67 * ts_mpa
        epf = 0.35
    return spf, epf

def hardness_method(hb, ts_mpa, e_mpa):
    """Hardness Method"""
    spf = 4.25 * hb + 225
    epf = 0.32 * (hb / 1000) ** (-1.24)
    return spf, epf

method_map = {1: hardness_method, 2: hardness_method, 3: hardness_method, 4: hardness_method}
method_names = {1: "Hardness Method", 2: "Hardness Method", 3: "Hardness Method", 4: "Hardness Method"}

def get_physics_params(hb_val, ts_mpa_val, e_mpa_val):
    """Get physics-based parameters based on material class"""
    method_name = "Unknown"
    spf_physics = epf_physics = None
    
    if hb_val <= 0 or np.isnan(hb_val):
        return np.nan, np.nan, "Invalid HB value"
    
    # Determine material class based on HB
    if hb_val <= HB_CLASS1_MAX:
        material_class = 1
    elif hb_val <= HB_CLASS2_MAX:
        material_class = 2
    elif hb_val <= HB_CLASS3_MAX:
        material_class = 3
    else:
        material_class = 4
    
    # Get method function and name
    method_func = method_map.get(material_class)
    method_name = method_names.get(material_class, "Unknown")
    
    if method_func:
        try:
            spf_physics, epf_physics = method_func(hb_val, ts_mpa_val, e_mpa_val)
        except Exception as e:
            return np.nan, np.nan, f"Error in {method_name}: {str(e)}"
    
    return spf_physics, epf_physics, method_name

# --- Helper function for Shear Conversion (New) ---
def convert_to_shear_parameters(spf_prime, b_fatigue, epf_prime, c_fatigue, E_gpa, TS_mpa, nu=0.3):
    tau_vm = spf_prime / np.sqrt(3)
    gamma_vm = np.sqrt(3) * epf_prime
    
    tau_mp = spf_prime / (1 + nu) 
    gamma_mp = 2 * epf_prime

    b0 = b_fatigue 
    c0 = c_fatigue

    conversion_method = "Unknown"
    tauf_prime, gammaf_prime = np.nan, np.nan

    if TS_mpa <= 1100:
        tauf_prime, gammaf_prime = tau_vm, gamma_vm
        conversion_method = "von Mises Criteria"
    elif TS_mpa >= 1696:
        tauf_prime, gammaf_prime = tau_mp, gamma_mp
        conversion_method = "Maximum Principal Stress/Strain Criteria"
    else:
        alpha = (TS_mpa - 1100) / (1696 - 1100)
        tauf_prime = (1 - alpha) * tau_vm + alpha * tau_mp
        gammaf_prime = (1 - alpha) * gamma_vm + alpha * gamma_mp
        conversion_method = f"Interpolated (von Mises to Max Principal, Î±={alpha:.2f})"

    shear_params = {
        'tauf_MPa': tauf_prime,
        'gammaf': gammaf_prime,
        'b0': b0,
        'c0': c0,
        'conversion_method': conversion_method
    }
    return shear_params

# --- Hybrid Model Prediction and Curve Generation (Modified) ---
def predict_fatigue_curves_hybrid(E_val_gpa, YS_val_mpa, TS_val_mpa, HB_val, model, scaler_X, 
                                  scalers_y_dict, target_cols_list,
                                  device, nu=0.3): 
    
    E_val_mpa = E_val_gpa * 1000 

    hb_processed_val = HB_val
    if HB_val is None or np.isnan(HB_val):
        if TS_val_mpa is not None and not np.isnan(TS_val_mpa):
            hb_processed_val = 1.8 * TS_val_mpa + 105 
        else: 
             raise ValueError("HB ê°’ê³¼ TS_MPa ê°’ ëª¨ë‘ ì œê³µë˜ì§€ ì•Šì•„ HB_processedë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    features_np = np.array([[E_val_mpa, YS_val_mpa, TS_val_mpa, hb_processed_val]], dtype=np.float32)
    
    scaled_features_np = scaler_X.transform(features_np)
    scaled_features = torch.tensor(scaled_features_np, dtype=torch.float32).to(device)

    model.eval()
    with torch.no_grad():
        predicted_params_scaled = model(scaled_features)
        
    predicted_params_orig_array = inverse_transform_targets(
        predicted_params_scaled.cpu().numpy(), 
        scalers_y_dict, 
        target_cols_list
    )
    
    predicted_params_orig = predicted_params_orig_array

    params_dict = dict(zip(target_cols_list, predicted_params_orig))

    sigma_f_prime = params_dict.get('spf_MPa')
    b_fatigue = params_dict.get('b')

    # Cell 6 ê¸°ì¤€: 'epf'ê°€ ë¡œê·¸ ë³€í™˜ëœ ì»¬ëŸ¼ì˜ ì´ë¦„ìœ¼ë¡œ params_dictì— í‚¤ë¡œ ì¡´ì¬
    # inverse_transform_targets í•¨ìˆ˜ê°€ ì´ë¯¸ í•´ë‹¹ ì»¬ëŸ¼ì— ëŒ€í•´ np.expm1ì„ ì ìš©í–ˆìŒ.
    if 'epf' in params_dict: # ë…¸íŠ¸ë¶ Cell 6ì˜ pkl ì €ì¥ ê¸°ì¤€
        epsilon_f_prime = params_dict.get('epf')
    elif 'epf_log' in params_dict: # 'epf_log'ë¡œ ì €ì¥ëœ pklì„ ìœ„í•œ ëŒ€ì²´ ê²½ë¡œ
        epsilon_f_prime = params_dict.get('epf_log')
    else:
        epsilon_f_prime = None 

    c_fatigue = params_dict.get('c')

    if sigma_f_prime is None or b_fatigue is None or epsilon_f_prime is None or c_fatigue is None:
        # ì˜¤ë¥˜ ë©”ì‹œì§€ì—ì„œ 'epf_log/epf' ëŒ€ì‹ , ì‹¤ì œë¡œ ì°¾ìœ¼ë ¤ê³  ì‹œë„í•œ í‚¤ë¥¼ ëª…ì‹œí•˜ëŠ” ê²ƒì´ ë” ì •í™•í•  ìˆ˜ ìˆìŒ
        # ì˜ˆë¥¼ ë“¤ì–´, target_cols_listì— ìˆëŠ” epf ê´€ë ¨ í‚¤ ('epf' ë˜ëŠ” 'epf_log')ë¥¼ ì‚¬ìš©
        epf_key_in_list = 'epf' if 'epf' in target_cols_list else 'epf_log' if 'epf_log' in target_cols_list else 'epf/epf_log'
        missing_keys = [key for key, val in zip(['spf_MPa', 'b', epf_key_in_list, 'c'], 
                                               [sigma_f_prime, b_fatigue, epsilon_f_prime, c_fatigue]) if val is None]
        raise ValueError(f"ëª¨ë¸ ì˜ˆì¸¡ì—ì„œ ë‹¤ìŒ í•„ìˆ˜ íŒŒë¼ë¯¸í„°ë“¤ì„ ì–»ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {missing_keys}. "
                         f"ì‚¬ìš©ëœ target_cols_list: {target_cols_list}, params_dictì— ìˆëŠ” í‚¤: {list(params_dict.keys())}")

    # E-N Curve (Tensile)
    Nf = np.logspace(1, 7, 100) 
    delta_epsilon_el_half = (sigma_f_prime / E_val_mpa) * (2 * Nf)**b_fatigue
    delta_epsilon_pl_half = epsilon_f_prime * (2 * Nf)**c_fatigue
    delta_epsilon_tot_half = delta_epsilon_el_half + delta_epsilon_pl_half
    sigma_a = sigma_f_prime * (2 * Nf)**b_fatigue

    results = {
        "Nf": Nf,
        "total_strain_amplitude": delta_epsilon_tot_half,
        "elastic_strain_amplitude": delta_epsilon_el_half,
        "plastic_strain_amplitude": delta_epsilon_pl_half,
        "stress_amplitude": sigma_a,
        "sigma_f_prime": sigma_f_prime,
        "b_fatigue": b_fatigue,
        "epsilon_f_prime": epsilon_f_prime,
        "c_fatigue": c_fatigue,
        "E_mpa": E_val_mpa
    }
    return results

# --- Load Model and Scalers ---
@st.cache_resource
def load_resources(model_path=MODEL_PATH, # ì „ì—­ ìƒìˆ˜ ì‚¬ìš©
                   scaler_x_path=SCALER_X_PATH, # ì „ì—­ ìƒìˆ˜ ì‚¬ìš©
                   scaler_y_path=SCALER_Y_PATH): # ì „ì—­ ìƒìˆ˜ ì‚¬ìš©
    # ëª¨ë¸ ë¡œë“œ
    model_hidden_dims = [192, 384, 352, 224]
    model_dropout_p = 0.35
    input_dim = 4 
    output_dim = 4 

    model = FatiguePINN(input_dim=input_dim, 
                        output_dim=output_dim, 
                        hidden_dims=model_hidden_dims, 
                        dropout_p=model_dropout_p)
    
    # ì „ì—­ device ë³€ìˆ˜ ì‚¬ìš©
    _device = device 

    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found: {model_path}")
    if not os.path.exists(scaler_x_path):
        raise FileNotFoundError(f"Scaler X file not found: {scaler_x_path}")
    if not os.path.exists(scaler_y_path):
        raise FileNotFoundError(f"Scaler Y file not found: {scaler_y_path}")

    if torch.cuda.is_available() and _device.type == 'cuda':
        model.load_state_dict(torch.load(model_path))
    elif torch.backends.mps.is_available() and _device.type == 'mps':
        model.load_state_dict(torch.load(model_path, map_location='mps'))
    else:
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
    model.to(_device)
    model.eval()

    scaler_X = joblib.load(scaler_x_path)
    
    data_y = joblib.load(scaler_y_path)
    
    # Cell 6 ê¸°ì¤€: pkl íŒŒì¼ì€ 'epf'ë¥¼ ë¡œê·¸ ë³€í™˜ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì €ì¥í•œë‹¤ê³  ê°€ì •
    expected_cols_for_model = ['spf_MPa', 'b', 'epf', 'c'] 

    if isinstance(data_y, dict) and 'scalers' in data_y and 'target_cols' in data_y:
        scalers_y_dict = data_y['scalers']
        target_cols_list = data_y['target_cols']
        
        if set(target_cols_list) != set(expected_cols_for_model):
            # ìˆœì„œëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜, í¬í•¨ëœ ì´ë¦„ ìì²´ê°€ ë‹¤ë¥¸ ê²½ìš° ê²½ê³ 
            # íŠ¹íˆ 'epf' ëŒ€ì‹  'epf_log'ê°€ ìˆê±°ë‚˜ ê·¸ ë°˜ëŒ€ì¸ ê²½ìš°ë¥¼ ê°ì§€í•˜ì—¬ ì•ˆë‚´
            if 'epf' in target_cols_list and 'epf_log' not in target_cols_list and 'epf_log' in expected_cols_for_model:
                 # ì´ ê²½ìš°ëŠ” expected_cols_for_modelì´ 'epf_log'ë¥¼ ê¸°ëŒ€í–ˆìœ¼ë‚˜ ì‹¤ì œë¡œëŠ” 'epf'ë§Œ ìˆì„ ë•Œ (í˜„ì¬ ë¡œì§ìƒ ë°œìƒ ì•ˆ í•¨)
                 pass 
            elif 'epf_log' in target_cols_list and 'epf' not in target_cols_list and 'epf' in expected_cols_for_model:
                # ì‹¤ì œ pklì— 'epf_log'ê°€ ìˆê³ , ìš°ë¦¬ëŠ” 'epf'ë¥¼ ê¸°ëŒ€í•˜ëŠ” ê²½ìš° (Cell 6 ê¸°ì¤€ê³¼ ë°˜ëŒ€)
                st.warning(
                    f"ê²½ê³ : ë¡œë“œëœ target_cols ({target_cols_list})ì— 'epf_log'ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. "
                    f"í˜„ì¬ ì•±ì€ ë…¸íŠ¸ë¶ Cell 6 ê¸°ì¤€ì— ë”°ë¼ '{expected_cols_for_model}' (ì¦‰, 'epf')ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤. "
                    f"inverse_transform_targets í•¨ìˆ˜ì—ì„œ 'epf_log'ë¥¼ ëŒ€ì²´ ì²˜ë¦¬í•˜ë ¤ê³  ì‹œë„í•˜ì§€ë§Œ, "
                    f"ì •í™•í•œ ì‘ë™ì„ ìœ„í•´ ë…¸íŠ¸ë¶ì—ì„œ target_colsì— 'epf'ë¥¼ ì‚¬ìš©í•˜ê³  scalers_y.pklì„ ì¬ìƒì„±í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                )
            else: # ê·¸ ì™¸ ì¼ë°˜ì ì¸ ì´ë¦„ ë¶ˆì¼ì¹˜
                 st.warning(
                    f"ê²½ê³ : ë¡œë“œëœ target_cols ({target_cols_list})ê°€ ì˜ˆìƒ ê¸°ë³¸ê°’ ({expected_cols_for_model})ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. "
                    f"ë¡œë“œëœ ê°’ì„ ì‚¬ìš©í•˜ë‚˜, ì˜ˆìƒì¹˜ ëª»í•œ ë™ì‘ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë…¸íŠ¸ë¶ì˜ scalers_y.pkl ì €ì¥ ë¶€ë¶„ì„ í™•ì¸í•˜ì„¸ìš”."
                )
        # ìˆœì„œ ì¼ì¹˜ ì—¬ë¶€ë„ ì¤‘ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë¦¬ìŠ¤íŠ¸ ì§ì ‘ ë¹„êµë„ ê³ ë ¤ (ì„ íƒì )
        if target_cols_list != expected_cols_for_model and set(target_cols_list) == set(expected_cols_for_model):
            st.info(f"ë¡œë“œëœ target_cols ({target_cols_list})ì˜ ìˆœì„œê°€ ì˜ˆìƒëœ ìˆœì„œ ({expected_cols_for_model})ì™€ ë‹¤ë¦…ë‹ˆë‹¤. ì´ë¦„ì€ ì¼ì¹˜í•˜ë¯€ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")

        missing_scalers = [col for col in target_cols_list if col not in scalers_y_dict]
        if missing_scalers:
            raise ValueError(f"'{scaler_y_path}' íŒŒì¼ì˜ 'scalers' ë”•ì…”ë„ˆë¦¬ì— ë‹¤ìŒ íƒ€ê²Ÿ ì»¬ëŸ¼ì— ëŒ€í•œ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤: {missing_scalers}. "
                             f"'target_cols'ëŠ” {target_cols_list} ì…ë‹ˆë‹¤.")

    elif isinstance(data_y, dict):
        st.warning(f"ê²½ê³ : '{scaler_y_path}' íŒŒì¼ì´ ì´ì „ í˜•ì‹ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤ (ìŠ¤ì¼€ì¼ëŸ¬ ë”•ì…”ë„ˆë¦¬ë§Œ í¬í•¨). "
                   f"'target_cols' ì •ë³´ê°€ ì—†ì–´ ëª¨ë¸ í•™ìŠµ ì‹œ ì˜ˆìƒë˜ëŠ” ê¸°ë³¸ê°’ {expected_cols_for_model}ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. "
                   f"ì •í™•í•œ ì‘ë™ì„ ìœ„í•´ ë…¸íŠ¸ë¶ì—ì„œ 'scalers_y.pkl' ì €ì¥ ë°©ì‹ì„ {'{'}'scalers': ..., 'target_cols': ...{'}'} í˜•íƒœë¡œ ì—…ë°ì´íŠ¸í•˜ê³ , "
                   f"target_colsë¥¼ '{expected_cols_for_model}'ë¡œ ì €ì¥í•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.")
        scalers_y_dict = data_y 
        target_cols_list = expected_cols_for_model 
        missing_keys_in_scaler = [key for key in target_cols_list if key not in scalers_y_dict]
        if missing_keys_in_scaler:
            raise ValueError(f"ì´ì „ í˜•ì‹ì˜ '{scaler_y_path}' íŒŒì¼ì—ì„œ ë¡œë“œëœ ìŠ¤ì¼€ì¼ëŸ¬ ë”•ì…”ë„ˆë¦¬ì— "
                             f"ì˜ˆìƒë˜ëŠ” ê¸°ë³¸ íƒ€ê²Ÿ ì»¬ëŸ¼({expected_cols_for_model})ì— ëŒ€í•œ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. "
                             f"ëˆ„ë½ëœ í‚¤: {missing_keys_in_scaler}")
    else:
        raise ValueError(f"'{scaler_y_path}' íŒŒì¼ì˜ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                         f"{'{'}'scalers': ..., 'target_cols': ...{'}'} í˜•ì‹ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.")

    if model.output_dim != len(target_cols_list):
        st.error(f"ëª¨ë¸ì˜ ì¶œë ¥ ì°¨ì›({model.output_dim})ê³¼ ë¡œë“œ/ê²°ì •ëœ íƒ€ê²Ÿ ì»¬ëŸ¼ì˜ ìˆ˜({len(target_cols_list)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                 f"ëª¨ë¸ ì•„í‚¤í…ì²˜ ë˜ëŠ” 'scalers_y.pkl' íŒŒì¼ì˜ 'target_cols'ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì‚¬ìš©ëœ íƒ€ê²Ÿ ì»¬ëŸ¼: {target_cols_list}")
        raise ValueError("Model output dimension and target columns mismatch.")
        
    return model, scaler_X, scalers_y_dict, target_cols_list

# --- Streamlit App Layout ---
st.set_page_config(layout="wide", page_title="Fatigue Life Predictor")
st.title('Fatigue Life Predictor (Îµ-N / Î³-N)')
st.write("Enter Monotonic Properties and Select mode, Get Prediction.")

# --- Session State ì´ˆê¸°í™” ---
if 'prediction_triggered' not in st.session_state:
    st.session_state.prediction_triggered = False
if 'user_inputs' not in st.session_state:
    st.session_state.user_inputs = {}
if 'en_results' not in st.session_state:
    st.session_state.en_results = None
if 'shear_results' not in st.session_state:
    st.session_state.shear_results = None
if 'physics_params' not in st.session_state:
    st.session_state.physics_params = None
if 'current_prediction_mode' not in st.session_state:
    st.session_state.current_prediction_mode = 'tensile'

# ë¦¬ì†ŒìŠ¤ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆ)
model, scaler_X, scalers_y_dict, target_cols_list = load_resources()

if model is None: st.stop()

# ì‚¬ì´ë“œë°”ì— ì…ë ¥ ì„¹ì…˜ ë°°ì¹˜
with st.sidebar:
    st.header("ì…ë ¥ íŒŒë¼ë¯¸í„°")
    st.subheader("ì¬ë£Œ íŠ¹ì„±")
    e_mod_gpa_input = st.number_input('íƒ„ì„± ê³„ìˆ˜ (E, GPa)', min_value=1.0, value=200.0, format='%.1f', help="GPa ë‹¨ìœ„ë¡œ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ê°•ì²  ì•½ 200 GPa)")
    ys_mpa_input = st.number_input('í•­ë³µ ê°•ë„ (YS, MPa)', min_value=1.0, value=500.0, format='%.1f')
    ts_mpa_input = st.number_input('ì¸ì¥ ê°•ë„ (UTS, MPa)', min_value=1.0, value=700.0, format='%.1f')
    hb_input_val = st.number_input('ë¸Œë¦¬ë„¬ ê²½ë„ (HB)', min_value=0.0, value=200.0, format='%.1f', help="ë¬¼ë¦¬ ê¸°ë°˜ spf/epf ê³„ì‚°ì— í•„ìš”í•©ë‹ˆë‹¤.")
    poisson_ratio_input = st.number_input("í¬ì•„ì†¡ ë¹„ (Î½)", min_value=0.0, max_value=0.5, value=0.3, step=0.01, format='%.2f', help="ì „ë‹¨ ê³„ì‚°ì— ì‚¬ìš©ë©ë‹ˆë‹¤")

    if hb_input_val <= 0:
         st.warning("ìœ íš¨í•œ HB ê°’ì„ ì…ë ¥í•˜ì„¸ìš”. HB ê°’ì´ 0 ì´í•˜ì´ë©´ ë¬¼ë¦¬ ê¸°ë°˜ ê²½í—˜ì‹ ê³„ì‚° ë° ì¼ë¶€ ì˜ˆì¸¡ ì •í™•ë„ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if st.button("í”¼ë¡œ ê±°ë™ ì˜ˆì¸¡ ì‹¤í–‰", use_container_width=True, type="primary"):
        st.session_state.prediction_triggered = True
        
        if not all_inputs_valid(e_mod_gpa_input * 1000, ys_mpa_input, ts_mpa_input, hb_input_val, poisson_ratio_input):
            st.error("ëª¨ë“  í•„ìˆ˜ ì…ë ¥ê°’ì„ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”. (E, YS, UTS > 0, 0 <= Î½ <= 0.5)")
            st.session_state.en_results = None 
            st.session_state.shear_results = None
            st.session_state.physics_params = None
        else:
            try:
                e_mod_mpa_for_calc = e_mod_gpa_input * 1000 # ë‚´ë¶€ ê³„ì‚°ìš© MPa ê°’
                temp_user_inputs = {
                    'E_gpa': e_mod_gpa_input, # GPaë¡œ ì €ì¥ (ì‚¬ìš©ì ì…ë ¥ê°’)
                    'E_mpa': e_mod_mpa_for_calc, # MPaë¡œ ì €ì¥ (ê³„ì‚°ìš©)
                    'YS_mpa': ys_mpa_input, 'TS_mpa': ts_mpa_input,
                    'HB': hb_input_val, 'nu': poisson_ratio_input
                }
                current_target_cols = target_cols_list 
                hb_to_pass = hb_input_val if hb_input_val is not None and hb_input_val > 0 else np.nan

                predicted_en_results = predict_fatigue_curves_hybrid(
                    e_mod_gpa_input, ys_mpa_input, ts_mpa_input, hb_to_pass, 
                    model, scaler_X, scalers_y_dict, 
                    current_target_cols, device
                )
                
                spf_phys, epf_phys, phys_method_name = get_physics_params(
                    hb_input_val if hb_input_val > 0 else np.nan, 
                    ts_mpa_input,
                    e_mod_mpa_for_calc # get_physics_paramsëŠ” MPa ë‹¨ìœ„ Eë¥¼ ë°›ìŒ
                )
                temp_physics_params = {
                    'spf_MPa_phys': spf_phys, 'epf_phys': epf_phys, 'method_name': phys_method_name
                }

                shear_calc_results = convert_to_shear_parameters(
                    spf_prime=predicted_en_results['sigma_f_prime'],
                    b_fatigue=predicted_en_results['b_fatigue'],
                    epf_prime=predicted_en_results['epsilon_f_prime'],
                    c_fatigue=predicted_en_results['c_fatigue'],
                    E_gpa=e_mod_gpa_input, TS_mpa=ts_mpa_input, nu=poisson_ratio_input 
                )
                G_mpa_calc = (predicted_en_results['E_mpa']) / (2 * (1 + poisson_ratio_input))
                shear_calc_results['G_mpa'] = G_mpa_calc
                
                st.session_state.user_inputs = temp_user_inputs
                st.session_state.en_results = predicted_en_results
                st.session_state.physics_params = temp_physics_params
                st.session_state.shear_results = shear_calc_results

                #st.sidebar.success("ì˜ˆì¸¡ ë° ê³„ì‚° ì™„ë£Œ!")

            except FileNotFoundError as fe:
                st.sidebar.error(f"í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {fe}.")
                st.session_state.en_results = None
                st.session_state.shear_results = None
                st.session_state.physics_params = None
            except ValueError as ve:
                st.sidebar.error(f"ì…ë ¥ê°’ ë˜ëŠ” ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {ve}")
                st.session_state.en_results = None
                st.session_state.shear_results = None
                st.session_state.physics_params = None
            except Exception as e:
                st.sidebar.error(f"ì˜ˆì¸¡ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
                st.session_state.en_results = None
                st.session_state.shear_results = None
                st.session_state.physics_params = None

# --- Main Area for Results ---
if st.session_state.prediction_triggered and st.session_state.en_results:
    # Create tabs: "ëª¨ë¸ ì˜ˆì¸¡ íŒŒë¼ë¯¸í„°", "ì¸ì¥ ê³¡ì„  (E-N)", "ì „ë‹¨ ê³¡ì„  (Î³-N)"
    # "ì…ë ¥ ìš”ì•½" íƒ­ ì œê±°
    tab_titles = ["í”¼ë¡œ íŒŒë¼ë¯¸í„°", "ì¸ì¥ ê³¡ì„  (E-N)", "ì „ë‹¨ ê³¡ì„  (Î³-N)"]
    # if st.session_state.current_prediction_mode == 'shear' and st.session_state.shear_results: # ì´ ì¡°ê±´ì€ ì´ì œ í•­ìƒ ì°¸ì´ê±°ë‚˜, shear_results ìœ ë¬´ë¡œ íŒë‹¨
    # í•­ìƒ ì „ë‹¨ íƒ­ì„ ë§Œë“¤ë„ë¡ í•˜ë˜, ë‚´ìš© í‘œì‹œëŠ” shear_results ìœ ë¬´ë¡œ ê²°ì •
    
    tabs = st.tabs(tab_titles)

    # Tab 1: Predicted Parameters (ê¸°ì¡´ Tab 2ì˜ ë‚´ìš© + ìˆ˜ì‹)
    with tabs[0]:
        st.subheader("ì¸ì¥ í”¼ë¡œ íŒŒë¼ë¯¸í„° ì˜ˆì¸¡ ê²°ê³¼")
        en_params = st.session_state.en_results
        phys_params = st.session_state.physics_params
        
        col1, col2 = st.columns(2)
        with col1:
            # method_name_display = phys_params.get('method_name', 'ê²½í—˜ì‹') # ì‚­ì œ
            # st.markdown(f"{method_name_display} ê¸°ë°˜ Ïƒf'") # ì‚­ì œ
            st.metric(r"ë¬¼ë¦¬ ì‹ ê³„ì‚° í”¼ë¡œ ê°•ë„ ê³„ìˆ˜ ($\sigma_f'$, Calculated Fatigue Strength Coeff.)", f"{phys_params.get('spf_MPa_phys', np.nan):.2f} MPa", 
                      help=f"ì…ë ¥ëœ HBê°’ê³¼ UTSë¥¼ ì‚¬ìš©í•˜ì—¬ ê²½í—˜ì‹ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. (ë°©ë²•: {phys_params.get('method_name', 'N/A')})")
            st.metric(r"í”¼ë¡œ ê°•ë„ ê³„ìˆ˜ ($\sigma_f'$, Fatigue Strength Coefficient)", f"{en_params.get('sigma_f_prime', np.nan):.2f} MPa")
            st.metric("í”¼ë¡œ ê°•ë„ ì§€ìˆ˜ (b, Fatigue Strength Exponent)", f"{en_params.get('b_fatigue', np.nan):.4f}")

        with col2:
            # method_name_display = phys_params.get('method_name', 'ê²½í—˜ì‹') # ì‚­ì œ
            # st.markdown(f"{method_name_display} ê¸°ë°˜ Îµf'") # ì‚­ì œ
            st.metric(r"ë¬¼ë¦¬ ì‹ ê³„ì‚° í”¼ë¡œ ì—°ì„± ê³„ìˆ˜ ($\epsilon_f'$, Calculated Fatigue Ductility Coeff.)", f"{phys_params.get('epf_phys', np.nan):.4f}",
                      help=f"ì…ë ¥ëœ HBê°’ê³¼ UTS, Eë¥¼ ì‚¬ìš©í•˜ì—¬ ê²½í—˜ì‹ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. (ë°©ë²•: {phys_params.get('method_name', 'N/A')})")
            st.metric(r"í”¼ë¡œ ì—°ì„± ê³„ìˆ˜ ($\epsilon_f'$, Fatigue Ductility Coefficient)", f"{en_params.get('epsilon_f_prime', np.nan):.4f}")
            st.metric("í”¼ë¡œ ì—°ì„± ì§€ìˆ˜ (c, Fatigue Ductility Exponent)", f"{en_params.get('c_fatigue', np.nan):.4f}")
        
        st.markdown("---_ì¸ì¥ Coffin-Manson ê´€ê³„ì‹_---")
        st.latex(r"\frac{\Delta\epsilon}{2} = \frac{\sigma'_f}{E}\,(2N_f)^b + \epsilon'_f\,(2N_f)^c")

        all_params_data = {
            'Parameter': [
                r"AI: í”¼ë¡œ ê°•ë„ ê³„ìˆ˜ ($\sigma_f'$, Fatigue Strength Coefficient, MPa)", 
                "AI: í”¼ë¡œ ê°•ë„ ì§€ìˆ˜ (b, Fatigue Strength Exponent)",
                r"AI: í”¼ë¡œ ì—°ì„± ê³„ìˆ˜ ($\epsilon_f'$, Fatigue Ductility Coefficient)", 
                "AI: í”¼ë¡œ ì—°ì„± ì§€ìˆ˜ (c, Fatigue Ductility Exponent)",
                r"Physics: ì¶”ì •ëœ í”¼ë¡œ ê°•ë„ ê³„ìˆ˜ ($\sigma_f'$, Estimated Fatigue Strength Coeff., MPa)", 
                r"Physics: ì¶”ì •ëœ í”¼ë¡œ ì—°ì„± ê³„ìˆ˜ ($\epsilon_f'$, Estimated Fatigue Ductility Coeff.)",
                "Physics: ì‚¬ìš©ëœ ê²½í—˜ì‹ ë°©ë²• (Method)"
            ],
            'Value': [
                f"{en_params.get('sigma_f_prime', np.nan):.2f}", 
                f"{en_params.get('b_fatigue', np.nan):.4f}",
                f"{en_params.get('epsilon_f_prime', np.nan):.4f}", 
                f"{en_params.get('c_fatigue', np.nan):.4f}",
                f"{phys_params.get('spf_MPa_phys', np.nan):.2f}", 
                f"{phys_params.get('epf_phys', np.nan):.4f}",
                str(phys_params.get('method_name', 'N/A'))
            ]
        }

        # ì „ë‹¨ íŒŒë¼ë¯¸í„° ë° ìˆ˜ì‹ ì¶”ê°€ (st.session_state.shear_results ìœ ë¬´ì— ë”°ë¼)
        if st.session_state.shear_results:
            st.divider()
            st.subheader("ì „ë‹¨ í”¼ë¡œ íŒŒë¼ë¯¸í„° ë³€í™˜")
            shear_params = st.session_state.shear_results
            s_col1, s_col2 = st.columns(2)
            s_col1.metric(r"ì „ë‹¨ í”¼ë¡œ ê°•ë„ ê³„ìˆ˜ ($\tau_f'$, Shear Fatigue Strength Coeff.)", f"{shear_params.get('tauf_MPa', np.nan):.2f} MPa")
            s_col1.metric(r"ì „ë‹¨ í”¼ë¡œ ê°•ë„ ì§€ìˆ˜ ($b_0$, Shear Fatigue Strength Exp.)", f"{shear_params.get('b0', np.nan):.4f}")
            s_col2.metric(r"ì „ë‹¨ í”¼ë¡œ ì—°ì„± ê³„ìˆ˜ ($\gamma_f'$, Shear Fatigue Ductility Coeff.)", f"{shear_params.get('gammaf', np.nan):.4f}")
            s_col2.metric(r"ì „ë‹¨ í”¼ë¡œ ì—°ì„± ì§€ìˆ˜ ($c_0$, Shear Fatigue Ductility Exp.)", f"{shear_params.get('c0', np.nan):.4f}")
            st.caption(f"ì „ë‹¨ ë³€í™˜ ë°©ë²• (Conversion Method): {shear_params.get('conversion_method', 'N/A')}")
            st.caption(f"ê³„ì‚°ëœ ì „ë‹¨ íƒ„ì„± ê³„ìˆ˜ (G, Shear Modulus): {shear_params.get('G_mpa', np.nan):.0f} MPa")
            
            st.markdown("---_ì „ë‹¨ Coffin-Manson ê´€ê³„ì‹ (ìœ ì‚¬ í˜•íƒœ)_---")
            st.latex(r"\frac{\Delta\gamma}{2} = \frac{\tau'_f}{G}\,(2N_f)^{b_0} + \gamma'_f\,(2N_f)^{c_0}")

            all_params_data['Parameter'].extend([
                r"Shear: ì „ë‹¨ í”¼ë¡œ ê°•ë„ ê³„ìˆ˜ ($\tau_f'$, Shear Fatigue Strength Coeff., MPa)", 
                r"Shear: ì „ë‹¨ í”¼ë¡œ ê°•ë„ ì§€ìˆ˜ ($b_0$, Shear Fatigue Strength Exp.)",
                r"Shear: ì „ë‹¨ í”¼ë¡œ ì—°ì„± ê³„ìˆ˜ ($\gamma_f'$, Shear Fatigue Ductility Coeff.)", 
                r"Shear: ì „ë‹¨ í”¼ë¡œ ì—°ì„± ì§€ìˆ˜ ($c_0$, Shear Fatigue Ductility Exp.)",
                "Shear: ì „ë‹¨ ë³€í™˜ ë°©ë²• (Conversion Method)", 
                "Shear: ì „ë‹¨ íƒ„ì„± ê³„ìˆ˜ (G, Shear Modulus, MPa)"
            ])
            all_params_data['Value'].extend([
                f"{shear_params.get('tauf_MPa', np.nan):.2f}", 
                f"{shear_params.get('b0', np.nan):.4f}",
                f"{shear_params.get('gammaf', np.nan):.4f}", 
                f"{shear_params.get('c0', np.nan):.4f}",
                str(shear_params.get('conversion_method', 'N/A')), 
                f"{shear_params.get('G_mpa', np.nan):.0f}"
            ])
        
        df_all_params = pd.DataFrame(all_params_data)
        csv_all_params = df_all_params.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ëª¨ë“  ì˜ˆì¸¡/ê³„ì‚° íŒŒë¼ë¯¸í„° CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_all_params,
            file_name="predicted_fatigue_parameters.csv",
            mime='text/csv',
            use_container_width=True # ë²„íŠ¼ í­ ì±„ìš°ê¸°
        )

    # Tab 2: Tensile Curve (E-N) (ê¸°ì¡´ Tab 3)
    with tabs[1]:
        st.subheader("E-N (ì¸ì¥ ë³€í˜•ë¥ -ìˆ˜ëª…) ê³¡ì„ ")
        en_data = st.session_state.en_results
        fig_en, ax_en = plt.subplots(figsize=(10, 6))
        
        reversals_en = en_data.get("Nf", np.array([]))
        total_strain_en = en_data.get("total_strain_amplitude")
        elastic_strain_en = en_data.get("elastic_strain_amplitude")
        plastic_strain_en = en_data.get("plastic_strain_amplitude")

        if total_strain_en is not None and not np.all(np.isnan(total_strain_en)):
            ax_en.loglog(reversals_en, total_strain_en, '-', label='Total Strain (Îµ_a,pred)', linewidth=2)
            if elastic_strain_en is not None: ax_en.loglog(reversals_en, elastic_strain_en, '--', label='Elastic Strain (pred)', alpha=0.8)
            if plastic_strain_en is not None: ax_en.loglog(reversals_en, plastic_strain_en, ':', label='Plastic Strain (pred)', alpha=0.8)
            
            ax_en.set_xlabel('Reversals to Failure (2Nf)')
            ax_en.set_ylabel('Strain Amplitude (Îµ_a)')
            ax_en.legend()
            ax_en.grid(True, which="both", ls="-", alpha=0.7)
            valid_strains = total_strain_en[~np.isnan(total_strain_en)]
            if len(valid_strains) > 0:
                ax_en.set_ylim(bottom=max(1e-5, np.min(valid_strains) * 0.5), top=np.max(valid_strains) * 1.5)
            else:
                ax_en.set_ylim(bottom=1e-5)
            ax_en.set_title('Predicted E-N (Strain-Life) Curve')
        else:
            ax_en.text(0.5, 0.5, 'E-N Curve data not available or contains NaNs.', ha='center', va='center', transform=ax_en.transAxes)
            ax_en.set_title('Predicted E-N (Strain-Life) Curve (Data N/A)')
        
        # st.latex(r"\\frac{\\Delta\\epsilon}{2} = \\frac{\\sigma'_f}{E}\\,(2N_f)^b + \\epsilon'_f\\,(2N_f)^c") # íŒŒë¼ë¯¸í„° íƒ­ìœ¼ë¡œ ì´ë™
        st.pyplot(fig_en)

        # Download buttons for E-N curve
        df_en_curve = pd.DataFrame({
            '2Nf': reversals_en,
            'Total_Strain_Amplitude': total_strain_en,
            'Elastic_Strain_Amplitude': elastic_strain_en,
            'Plastic_Strain_Amplitude': plastic_strain_en,
            'Stress_Amplitude_MPa': en_data.get("stress_amplitude")
        })
        csv_en_curve = df_en_curve.to_csv(index=False).encode('utf-8')
        
        img_en_buf = io.BytesIO()
        fig_en.savefig(img_en_buf, format="png", dpi=300)
        img_en_buf.seek(0)

        dl_col1, dl_col2 = st.columns(2)
        with dl_col1:
            st.download_button(label="E-N ê³¡ì„  ë°ì´í„° (CSV) ë‹¤ìš´ë¡œë“œ", data=csv_en_curve, file_name="en_curve_data.csv", mime="text/csv", use_container_width=True)
        with dl_col2:
            st.download_button(label="E-N ê³¡ì„  ì´ë¯¸ì§€ (PNG) ë‹¤ìš´ë¡œë“œ", data=img_en_buf, file_name="en_curve_plot.png", mime="image/png", use_container_width=True)

        with st.expander("E-N ê³¡ì„  ìˆ˜ì¹˜ ë°ì´í„° ë³´ê¸°"):
            if not df_en_curve.empty:
                # ìˆ«ì í˜•ì‹ ì§€ì • (ì˜ˆ: ì†Œìˆ˜ì  4ìë¦¬ ë˜ëŠ” ê³¼í•™ì  í‘œê¸°ë²•)
                st.dataframe(df_en_curve.style.format({
                    col: '{:.4e}' for col in df_en_curve.columns if df_en_curve[col].dtype == 'float'
                }))
            else:
                st.write("í‘œì‹œí•  E-N ê³¡ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # Tab 3: Shear Curve (Gamma-N) - Conditional (ê¸°ì¡´ Tab 4)
    # ì „ë‹¨ ê²°ê³¼ëŠ” í•­ìƒ ê³„ì‚°ë˜ë¯€ë¡œ, st.session_state.shear_results ìœ ë¬´ë¡œ í‘œì‹œ ê²°ì •
    if st.session_state.shear_results:
        with tabs[2]: # íƒ­ ì¸ë±ìŠ¤ ìˆ˜ì • (0, 1, 2)
            st.subheader("Gamma-N (ì „ë‹¨ ë³€í˜•ë¥ -ìˆ˜ëª…) ê³¡ì„ ")
            shear_data = st.session_state.shear_results
            en_base_data = st.session_state.en_results 
            
            fig_gn, ax_gn = plt.subplots(figsize=(10, 6))
            reversals_gn = en_base_data.get("Nf", np.array([])) 

            tauf_prime = shear_data.get('tauf_MPa')
            gammaf_prime = shear_data.get('gammaf')
            b0 = shear_data.get('b0')
            c0 = shear_data.get('c0')
            G_mpa = shear_data.get('G_mpa')

            if all(val is not None and not np.isnan(val) for val in [tauf_prime, gammaf_prime, b0, c0, G_mpa]) and G_mpa > 0:
                elastic_shear_strain_gn = (tauf_prime / G_mpa) * (reversals_gn ** b0)
                plastic_shear_strain_gn = gammaf_prime * (reversals_gn ** c0)
                total_shear_strain_gn = elastic_shear_strain_gn + plastic_shear_strain_gn
                
                ax_gn.loglog(reversals_gn, total_shear_strain_gn, '-', label='Total Shear Strain (Î³_a,pred)', linewidth=2)
                ax_gn.loglog(reversals_gn, elastic_shear_strain_gn, '--', label='Elastic Shear Strain (pred)', alpha=0.8)
                ax_gn.loglog(reversals_gn, plastic_shear_strain_gn, ':', label='Plastic Shear Strain (pred)', alpha=0.8)

                ax_gn.set_xlabel('Reversals to Failure (2Nf)')
                ax_gn.set_ylabel('Shear Strain Amplitude (Î³_a)')
                ax_gn.legend()
                ax_gn.grid(True, which="both", ls="-", alpha=0.7)
                valid_strains_gn = total_shear_strain_gn[~np.isnan(total_shear_strain_gn)]
                if len(valid_strains_gn) > 0:
                     ax_gn.set_ylim(bottom=max(1e-5, np.min(valid_strains_gn) * 0.5), top=np.max(valid_strains_gn) * 1.5)
                else:
                    ax_gn.set_ylim(bottom=1e-5)
                ax_gn.set_title('Predicted Gamma-N (Shear Strain-Life) Curve')
                st.caption(f"ì „ë‹¨ ë³€í™˜ ë°©ë²•: {shear_data.get('conversion_method', 'N/A')}") # ë³€í™˜ ë°©ë²•ì€ ì—¬ê¸°ì— ìœ ì§€
            else:
                ax_gn.text(0.5, 0.5, 'Gamma-N Curve data not available or contains NaNs.', ha='center', va='center', transform=ax_gn.transAxes)
                ax_gn.set_title('Predicted Gamma-N (Shear Strain-Life) Curve (Data N/A)')
                st.warning("ì „ë‹¨ í”¼ë¡œ íŒŒë¼ë¯¸í„° ê³„ì‚°ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ì „ë‹¨ íƒ„ì„± ê³„ìˆ˜ê°€ 0 ë˜ëŠ” NaNì´ë¯€ë¡œ Gamma-N ê³¡ì„ ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # st.latex(r"\\frac{\\Delta\\gamma}{2} = \\frac{\\tau'_f}{G}\\,(2N_f)^{b_0} + \\gamma'_f\\,(2N_f)^{c_0}") # íŒŒë¼ë¯¸í„° íƒ­ìœ¼ë¡œ ì´ë™
            st.pyplot(fig_gn)

            # Download buttons for Gamma-N curve
            # total_shear_strain_gn ë“±ì´ ê³„ì‚°ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í™•ì¸ í›„ DataFrame ìƒì„±
            df_gn_data_to_save = {}
            if 'total_shear_strain_gn' in locals() and total_shear_strain_gn is not None:
                df_gn_data_to_save['Total_Shear_Strain_Amplitude'] = total_shear_strain_gn
            if 'elastic_shear_strain_gn' in locals() and elastic_shear_strain_gn is not None:
                df_gn_data_to_save['Elastic_Shear_Strain_Amplitude'] = elastic_shear_strain_gn
            if 'plastic_shear_strain_gn' in locals() and plastic_shear_strain_gn is not None:
                df_gn_data_to_save['Plastic_Shear_Strain_Amplitude'] = plastic_shear_strain_gn
            
            if df_gn_data_to_save: # ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´
                df_gn_data_to_save['2Nf'] = reversals_gn # 2NfëŠ” í•­ìƒ ìˆìŒ
                df_gn_curve = pd.DataFrame(df_gn_data_to_save)
                # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ì˜ (2Nfê°€ ë§¨ ì•ìœ¼ë¡œ ì˜¤ë„ë¡)
                cols_order = ['2Nf'] + [col for col in df_gn_data_to_save if col != '2Nf']
                df_gn_curve = df_gn_curve[cols_order]
                csv_gn_curve = df_gn_curve.to_csv(index=False).encode('utf-8')
                gn_csv_disabled = False
            else:
                csv_gn_curve = pd.DataFrame().to_csv(index=False).encode('utf-8')
                gn_csv_disabled = True

            img_gn_buf = io.BytesIO()
            fig_gn.savefig(img_gn_buf, format="png", dpi=300)
            img_gn_buf.seek(0)
            
            dl_gn_col1, dl_gn_col2 = st.columns(2)
            with dl_gn_col1:
                st.download_button(label="Gamma-N ê³¡ì„  ë°ì´í„° (CSV) ë‹¤ìš´ë¡œë“œ", data=csv_gn_curve, file_name="gamma_n_curve_data.csv", mime="text/csv",
                                   disabled=gn_csv_disabled, use_container_width=True)
            with dl_gn_col2:
                st.download_button(label="Gamma-N ê³¡ì„  ì´ë¯¸ì§€ (PNG) ë‹¤ìš´ë¡œë“œ", data=img_gn_buf, file_name="gamma_n_curve_plot.png", mime="image/png", use_container_width=True)
            
            with st.expander("Gamma-N ê³¡ì„  ìˆ˜ì¹˜ ë°ì´í„° ë³´ê¸°"):
                # df_gn_curveëŠ” ì´ë¯¸ ìœ„ì—ì„œ ìƒì„±ë˜ì—ˆê±°ë‚˜ ë¹ˆ DataFrameì„
                if not csv_gn_curve == pd.DataFrame().to_csv(index=False).encode('utf-8'): # gn_csv_disabled ëŒ€ì‹  csv ë‚´ìš©ìœ¼ë¡œ í™•ì¸
                    # df_gn_curveë¥¼ ë‹¤ì‹œ ë§Œë“¤ê±°ë‚˜, ì´ë¯¸ ìˆëŠ” df_gn_curveë¥¼ ì‚¬ìš©
                    # ìœ„ì—ì„œ df_gn_curveê°€ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œ ë‹¤ì‹œ ë§Œë“¤ê±°ë‚˜, ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                    if 'df_gn_curve' in locals() and not df_gn_curve.empty:
                         st.dataframe(df_gn_curve.style.format({
                            col: '{:.4e}' for col in df_gn_curve.columns if df_gn_curve[col].dtype == 'float'
                        }))
                    elif df_gn_data_to_save: # df_gn_data_to_saveë¡œ DataFrameì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤ë©´
                        temp_df_gn = pd.DataFrame(df_gn_data_to_save)
                        cols_order_temp = ['2Nf'] + [col for col in df_gn_data_to_save if col != '2Nf']
                        temp_df_gn = temp_df_gn[cols_order_temp]
                        st.dataframe(temp_df_gn.style.format({
                            col: '{:.4e}' for col in temp_df_gn.columns if temp_df_gn[col].dtype == 'float'
                        }))
                    else:
                        st.write("í‘œì‹œí•  Gamma-N ê³¡ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ê³„ì‚° ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„° ì—†ìŒ).")
                else:
                    st.write("í‘œì‹œí•  Gamma-N ê³¡ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë§Œì•½ shear_resultsê°€ ì—†ìœ¼ë©´ (ì˜ˆì™¸ ë°œìƒ ë“±) ì „ë‹¨ íƒ­ì„ í‘œì‹œí•˜ì§€ ì•Šê±°ë‚˜, ì˜¤ë¥˜ ë©”ì‹œì§€ë§Œ í‘œì‹œí•  ìˆ˜ ìˆìŒ
    # í˜„ì¬ ë¡œì§ì—ì„œëŠ” tabs[2]ê°€ í•­ìƒ ì „ë‹¨ íƒ­ì´ë¯€ë¡œ, shear_resultsê°€ ì—†ì„ ê²½ìš° ìœ„ì—ì„œ ë‚´ìš©ì´ ì•ˆê·¸ë ¤ì§

elif not st.session_state.prediction_triggered:
    st.info('ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì¬ë£Œ ë¬¼ì„±ì¹˜ë¥¼ ì…ë ¥í•˜ê³ , ì˜ˆì¸¡ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.') # ë¬¸êµ¬ ìˆ˜ì •ë¨

st.divider() # ì‹œê°ì  êµ¬ë¶„ì„ ìœ„í•œ ì„  ì¶”ê°€
st.markdown(
    """
    <div style="text-align: center; color: grey; font-size: 0.8em;">
        Â© 2025 YeoJoon Yoon. All Rights Reserved.<br>
        Contact: <a href="mailto:goat@sogang.ac.kr">goat@sogang.ac.kr</a>
    </div>
    """,
    unsafe_allow_html=True
)

# ì•± ì‹¤í–‰ ì•ˆë‚´ (í„°ë¯¸ë„ì—ì„œ ì§ì ‘ ì‹¤í–‰ ì‹œ í•„ìš”)
# streamlit run FatiguePredictor0528.py
