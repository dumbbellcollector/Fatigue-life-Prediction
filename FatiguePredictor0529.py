import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import joblib
import os
import pandas as pd
import io # For image download

# Import the new module
import composition_to_properties as ctp

# --- File Paths (Global Constants) ---
# Attempt to determine script directory for robust pathing
try:
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
except NameError: # Occurs when running in some environments like notebooks directly
    BASE_DIR = os.getcwd()

MODEL_PATH = os.path.join(BASE_DIR, 'best_fatigue_pinn_model.pth')
SCALER_X_PATH = os.path.join(BASE_DIR, 'scaler_X.pkl')
SCALER_Y_PATH = os.path.join(BASE_DIR, 'scalers_y.pkl')

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
print(f"Streamlit App: Using device: {device}")

# --- Input Validation Function ---
def validate_monotonic_inputs(e_mod_gpa, ys_mpa, ts_mpa, hb_input, poisson_ratio):
    error_messages = []
    if e_mod_gpa is None or e_mod_gpa <= 0: error_messages.append("íƒ„ì„± ê³„ìˆ˜(E)ëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤ (GPa ë‹¨ìœ„).")
    if ys_mpa is None or ys_mpa <= 0: error_messages.append("í•­ë³µ ê°•ë„(YS)ëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤ (MPa ë‹¨ìœ„).")
    if ts_mpa is None or ts_mpa <= 0: error_messages.append("ì¸ì¥ ê°•ë„(TS)ëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤ (MPa ë‹¨ìœ„).")
    if hb_input is not None and hb_input < 0: error_messages.append("ë¸Œë¦¬ë„¬ ê²½ë„(HB)ëŠ” ìŒìˆ˜ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if poisson_ratio is None or not (0 <= poisson_ratio <= 0.5): error_messages.append("í¬ì•„ì†¡ ë¹„(Î½)ëŠ” 0.0ì—ì„œ 0.5 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    if ys_mpa is not None and ts_mpa is not None and ys_mpa > ts_mpa and ys_mpa > 0 and ts_mpa > 0 :
        st.sidebar.warning("ê²½ê³ : í•­ë³µ ê°•ë„(YS)ê°€ ì¸ì¥ ê°•ë„(TS)ë³´ë‹¤ í½ë‹ˆë‹¤. ì…ë ¥ê°’ì„ í™•ì¸í•˜ì„¸ìš”.")

    if error_messages:
        for msg in error_messages:
            st.sidebar.error(msg)
        return False
    return True

def validate_composition_inputs(composition: dict):
    error_messages = []
    for element, value in composition.items():
        if value is None or value < 0: # Also check for None
            error_messages.append(f"{element}ì˜ ì¡°ì„±ë¹„ëŠ” 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    # Optional: Check sum, but usually Fe is balance
    # total_comp = sum(v for v in composition.values() if v is not None)
    # if total_comp > 100:
    #     error_messages.append(f"ì…ë ¥ëœ ì¡°ì„±ì˜ í•©ê³„({total_comp:.2f} wt%)ê°€ 100 wt%ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")

    if error_messages:
        for msg in error_messages:
            st.sidebar.error(msg)
        return False
    return True

# --- main.ipynbì˜ inverse_transform_targets í•¨ìˆ˜ ---
def inverse_transform_targets(y_scaled_data, scalers_y_dict, target_cols_list):
    if y_scaled_data.ndim == 1:
        y_scaled_data = y_scaled_data.reshape(1, -1)
        
    y_transformed_individually = np.zeros_like(y_scaled_data)
    for i, col_name in enumerate(target_cols_list):
        if col_name not in scalers_y_dict: 
            raise KeyError(f"Scaler for target '{col_name}' not found in scalers_y_dict. Available keys: {list(scalers_y_dict.keys())}")
        y_transformed_individually[:, i] = scalers_y_dict[col_name].inverse_transform(y_scaled_data[:, i].reshape(-1, 1)).flatten()
    
    y_orig_scale = y_transformed_individually.copy()
    
    log_col_expected_name = 'epf' 
    fallback_log_col_name = 'epf_log'

    if log_col_expected_name in target_cols_list:
        try:
            current_log_col_idx = target_cols_list.index(log_col_expected_name)
            y_orig_scale[:, current_log_col_idx] = np.expm1(y_transformed_individually[:, current_log_col_idx])
        except ValueError:
            st.warning(f"'{log_col_expected_name}' was in target_cols_list but index could not be found. Skipping expm1 transformation for it.")
    elif fallback_log_col_name in target_cols_list: 
        try:
            current_fallback_log_col_idx = target_cols_list.index(fallback_log_col_name)
            st.info(f"Note: Found '{fallback_log_col_name}' in target_cols and applying expm1. "
                    f"The primary expected log-column name is '{log_col_expected_name}'.")
            y_orig_scale[:, current_fallback_log_col_idx] = np.expm1(y_transformed_individually[:, current_fallback_log_col_idx])
        except ValueError:
            st.warning(f"'{fallback_log_col_name}' was in target_cols_list but index could not be found. Skipping expm1 transformation for it.")
            
    if y_scaled_data.shape[0] == 1 and y_orig_scale.shape[0] == 1:
         return y_orig_scale.flatten()
    return y_orig_scale

# --- ëª¨ë¸ ì •ì˜ ë³µì œ (FatiguePINN) ---
class FatiguePINN(nn.Module):
    def __init__(self, input_dim, output_dim, hidden_dims=[128, 256, 128], dropout_p=0.1):
        super().__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.dropout_p = dropout_p 

        layers = []
        last_dim = input_dim
        for i, hidden_dim in enumerate(hidden_dims):
            layers.append(nn.Linear(last_dim, hidden_dim))
            layers.append(nn.ReLU())
            if self.dropout_p > 0:
                layers.append(nn.Dropout(p=self.dropout_p))
            last_dim = hidden_dim
        
        layers.append(nn.Linear(last_dim, output_dim))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

# --- Empirical Method Functions ---
HB_CLASS1_MAX = 150; HB_CLASS2_MAX = 500; HB_CLASS3_MAX = 700

def modified_universal_slopes(ts_mpa, e_mpa):
    spf = 1.9 * ts_mpa
    epf = 0.623 * (ts_mpa / e_mpa) ** 0.832
    return spf, epf

def uniform_material_law(ts_mpa, e_mpa):
    if ts_mpa < 750:
        spf = 1.5 * ts_mpa
        epf = 0.59 * (ts_mpa / e_mpa) ** 0.58
    else:
        spf = 1.67 * ts_mpa
        epf = 0.35
    return spf, epf

def hardness_method(hb, ts_mpa, e_mpa):
    spf = 4.25 * hb + 225
    epf = 0.32 * (hb / 1000) ** (-1.24)
    return spf, epf

method_map = {1: hardness_method, 2: hardness_method, 3: hardness_method, 4: hardness_method}
method_names = {1: "Hardness Method", 2: "Hardness Method", 3: "Hardness Method", 4: "Hardness Method"}

def get_physics_params(hb_val, ts_mpa_val, e_mpa_val):
    method_name = "Unknown"
    spf_physics = epf_physics = None
    
    if hb_val is None or hb_val <= 0 or np.isnan(hb_val):
        return np.nan, np.nan, "ìœ íš¨í•œ HB ê°’ì´ ì—†ì–´ ë¬¼ë¦¬ ê¸°ë°˜ ê³„ì‚° ë¶ˆê°€"
    
    if ts_mpa_val is None or e_mpa_val is None or ts_mpa_val <=0 or e_mpa_val <=0: # Added check for TS, E
        return np.nan, np.nan, "TS ë˜ëŠ” E ê°’ì´ ìœ íš¨í•˜ì§€ ì•Šì•„ ë¬¼ë¦¬ ê¸°ë°˜ ê³„ì‚° ë¶ˆê°€"

    if hb_val <= HB_CLASS1_MAX: material_class = 1
    elif hb_val <= HB_CLASS2_MAX: material_class = 2
    elif hb_val <= HB_CLASS3_MAX: material_class = 3
    else: material_class = 4
    
    method_func = method_map.get(material_class)
    method_name = method_names.get(material_class, "Unknown")
    
    if method_func:
        try:
            spf_physics, epf_physics = method_func(hb_val, ts_mpa_val, e_mpa_val)
        except Exception as e:
            return np.nan, np.nan, f"{method_name} ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    return spf_physics, epf_physics, method_name

# --- Helper function for Shear Conversion (New) ---
def convert_to_shear_parameters(spf_prime, b_fatigue, epf_prime, c_fatigue, E_gpa, TS_mpa, nu=0.3):
    # Ensure all inputs are valid numbers before proceeding
    if any(val is None or np.isnan(val) for val in [spf_prime, b_fatigue, epf_prime, c_fatigue, E_gpa, TS_mpa, nu]):
        st.warning("ì „ë‹¨ ë³€í™˜ì— í•„ìš”í•œ ì¼ë¶€ íŒŒë¼ë¯¸í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (NaN ë˜ëŠ” None)")
        return { # Return a structure with NaNs to prevent downstream errors
            'tauf_MPa': np.nan, 'gammaf': np.nan, 'b0': np.nan, 'c0': np.nan,
            'conversion_method': "ì…ë ¥ íŒŒë¼ë¯¸í„° ë¶€ì¡±/ë¬´íš¨", 'G_mpa': np.nan
        }

    tau_vm = spf_prime / np.sqrt(3)
    gamma_vm = np.sqrt(3) * epf_prime
    
    tau_mp = spf_prime / (1 + nu) 
    gamma_mp = 2 * epf_prime

    b0 = b_fatigue 
    c0 = c_fatigue

    conversion_method = "Unknown"
    tauf_prime_calc, gammaf_prime_calc = np.nan, np.nan # Renamed to avoid conflict

    if TS_mpa <= 1100:
        tauf_prime_calc, gammaf_prime_calc = tau_vm, gamma_vm
        conversion_method = "von Mises Criteria"
    elif TS_mpa >= 1696:
        tauf_prime_calc, gammaf_prime_calc = tau_mp, gamma_mp
        conversion_method = "Maximum Principal Stress/Strain Criteria"
    else:
        alpha = (TS_mpa - 1100) / (1696 - 1100)
        tauf_prime_calc = (1 - alpha) * tau_vm + alpha * tau_mp
        gammaf_prime_calc = (1 - alpha) * gamma_vm + alpha * gamma_mp
        conversion_method = f"Interpolated (von Mises to Max Principal, Î±={alpha:.2f})"

    E_mpa_internal = E_gpa * 1000
    G_mpa_internal = E_mpa_internal / (2 * (1 + nu)) if E_mpa_internal > 0 and nu is not None else np.nan

    shear_params = {
        'tauf_MPa': tauf_prime_calc,
        'gammaf': gammaf_prime_calc,
        'b0': b0,
        'c0': c0,
        'conversion_method': conversion_method,
        'G_mpa': G_mpa_internal
    }
    return shear_params

# --- Hybrid Model Prediction and Curve Generation (Modified) ---
def predict_fatigue_curves_hybrid(E_val_gpa, YS_val_mpa, TS_val_mpa, HB_val, model, scaler_X, 
                                  scalers_y_dict, target_cols_list,
                                  device): 
    
    if any(v is None for v in [E_val_gpa, YS_val_mpa, TS_val_mpa]): # HB_val can be None
        raise ValueError("E, YS, TS ê°’ì€ ë°˜ë“œì‹œ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")

    E_val_mpa = E_val_gpa * 1000 

    hb_processed_val = HB_val
    if HB_val is None or np.isnan(HB_val) or HB_val <= 0: # Added HB_val <= 0
        if TS_val_mpa is not None and not np.isnan(TS_val_mpa) and TS_val_mpa > 0:
            hb_processed_val = 1.8 * TS_val_mpa + 105 
            st.sidebar.info(f"HBê°’ì´ ì œê³µë˜ì§€ ì•Šê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì•„ TS ({TS_val_mpa} MPa)ë¡œë¶€í„° ì¶”ì •ëœ HB ({hb_processed_val:.1f})ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else: 
             raise ValueError("HB ê°’ê³¼ TS_MPa ê°’ ëª¨ë‘ ìœ íš¨í•˜ì§€ ì•Šì•„ HB_processedë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Ensure all features for model are valid numbers
    if any(np.isnan(v) or v is None for v in [E_val_mpa, YS_val_mpa, TS_val_mpa, hb_processed_val]):
        raise ValueError(f"ëª¨ë¸ ì…ë ¥ íŠ¹ì§• ì¤‘ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì´ ìˆìŠµë‹ˆë‹¤: E={E_val_mpa}, YS={YS_val_mpa}, TS={TS_val_mpa}, HB_proc={hb_processed_val}")


    features_np = np.array([[E_val_mpa, YS_val_mpa, TS_val_mpa, hb_processed_val]], dtype=np.float32)
    
    scaled_features_np = scaler_X.transform(features_np)
    scaled_features = torch.tensor(scaled_features_np, dtype=torch.float32).to(device)

    model.eval()
    with torch.no_grad():
        predicted_params_scaled = model(scaled_features)
        
    predicted_params_orig_array = inverse_transform_targets(
        predicted_params_scaled.cpu().numpy(), 
        scalers_y_dict, 
        target_cols_list
    )
    
    predicted_params_orig = predicted_params_orig_array

    params_dict = dict(zip(target_cols_list, predicted_params_orig))

    sigma_f_prime = params_dict.get('spf_MPa')
    b_fatigue = params_dict.get('b')

    if 'epf' in params_dict:
        epsilon_f_prime = params_dict.get('epf')
    elif 'epf_log' in params_dict:
        epsilon_f_prime = params_dict.get('epf_log')
    else:
        epsilon_f_prime = None 

    c_fatigue = params_dict.get('c')

    if sigma_f_prime is None or b_fatigue is None or epsilon_f_prime is None or c_fatigue is None:
        epf_key_in_list = 'epf' if 'epf' in target_cols_list else 'epf_log' if 'epf_log' in target_cols_list else 'epf/epf_log'
        missing_keys = [key for key, val in zip(['spf_MPa', 'b', epf_key_in_list, 'c'], 
                                               [sigma_f_prime, b_fatigue, epsilon_f_prime, c_fatigue]) if val is None]
        raise ValueError(f"ëª¨ë¸ ì˜ˆì¸¡ì—ì„œ ë‹¤ìŒ í•„ìˆ˜ íŒŒë¼ë¯¸í„°ë“¤ì„ ì–»ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {missing_keys}. "
                         f"ì‚¬ìš©ëœ target_cols_list: {target_cols_list}, params_dictì— ìˆëŠ” í‚¤: {list(params_dict.keys())}")

    Nf = np.logspace(1, 7, 100) 
    delta_epsilon_el_half = (sigma_f_prime / E_val_mpa) * (2 * Nf)**b_fatigue
    delta_epsilon_pl_half = epsilon_f_prime * (2 * Nf)**c_fatigue
    delta_epsilon_tot_half = delta_epsilon_el_half + delta_epsilon_pl_half
    sigma_a = sigma_f_prime * (2 * Nf)**b_fatigue

    results = {
        "Nf": Nf,
        "total_strain_amplitude": delta_epsilon_tot_half,
        "elastic_strain_amplitude": delta_epsilon_el_half,
        "plastic_strain_amplitude": delta_epsilon_pl_half,
        "stress_amplitude": sigma_a,
        "sigma_f_prime": sigma_f_prime,
        "b_fatigue": b_fatigue,
        "epsilon_f_prime": epsilon_f_prime,
        "c_fatigue": c_fatigue,
        "E_mpa": E_val_mpa, 
        "HB_processed_for_prediction": hb_processed_val
    }
    return results

# --- Load Model and Scalers ---
@st.cache_resource
def load_resources(model_path=MODEL_PATH, scaler_x_path=SCALER_X_PATH, scaler_y_path=SCALER_Y_PATH):
    model_hidden_dims = [192, 384, 352, 224]
    model_dropout_p = 0.35
    input_dim = 4 
    output_dim = 4 

    model = FatiguePINN(input_dim=input_dim, output_dim=output_dim, 
                        hidden_dims=model_hidden_dims, dropout_p=model_dropout_p)
    
    _device = device 

    if not os.path.exists(model_path): raise FileNotFoundError(f"Model file not found: {model_path}")
    if not os.path.exists(scaler_x_path): raise FileNotFoundError(f"Scaler X file not found: {scaler_x_path}")
    if not os.path.exists(scaler_y_path): raise FileNotFoundError(f"Scaler Y file not found: {scaler_y_path}")

    map_location = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'
    model.load_state_dict(torch.load(model_path, map_location=map_location))
    model.to(_device)
    model.eval()

    scaler_X = joblib.load(scaler_x_path)
    data_y = joblib.load(scaler_y_path)
    
    expected_cols_for_model = ['spf_MPa', 'b', 'epf', 'c'] 

    if isinstance(data_y, dict) and 'scalers' in data_y and 'target_cols' in data_y:
        scalers_y_dict = data_y['scalers']
        target_cols_list = data_y['target_cols']
        
        if set(target_cols_list) != set(expected_cols_for_model):
            if 'epf_log' in target_cols_list and 'epf' not in target_cols_list and 'epf' in expected_cols_for_model:
                st.warning(
                    f"ê²½ê³ : ë¡œë“œëœ target_cols ({target_cols_list})ì— 'epf_log'ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. "
                    f"ì•±ì€ '{expected_cols_for_model}' ('epf')ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤. 'epf_log'ë¥¼ ëŒ€ì²´ ì²˜ë¦¬í•©ë‹ˆë‹¤."
                )
            else:
                 st.warning(
                    f"ê²½ê³ : ë¡œë“œëœ target_cols ({target_cols_list})ê°€ ì˜ˆìƒ ê¸°ë³¸ê°’ ({expected_cols_for_model})ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. "
                    f"ë¡œë“œëœ ê°’ì„ ì‚¬ìš©í•˜ë‚˜, ì˜ˆìƒì¹˜ ëª»í•œ ë™ì‘ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
        if target_cols_list != expected_cols_for_model and set(target_cols_list) == set(expected_cols_for_model):
            st.info(f"ë¡œë“œëœ target_cols ({target_cols_list})ì˜ ìˆœì„œê°€ ì˜ˆìƒëœ ìˆœì„œ ({expected_cols_for_model})ì™€ ë‹¤ë¦…ë‹ˆë‹¤. ì´ë¦„ì€ ì¼ì¹˜í•˜ë¯€ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")

        missing_scalers = [col for col in target_cols_list if col not in scalers_y_dict]
        if missing_scalers:
            raise ValueError(f"'{scaler_y_path}'ì˜ 'scalers'ì— ë‹¤ìŒ íƒ€ê²Ÿ ì»¬ëŸ¼ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤: {missing_scalers}.")

    elif isinstance(data_y, dict):
        st.warning(f"ê²½ê³ : '{scaler_y_path}' íŒŒì¼ì´ ì´ì „ í˜•ì‹ì…ë‹ˆë‹¤. ê¸°ë³¸ íƒ€ê²Ÿ ì»¬ëŸ¼ {expected_cols_for_model}ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        scalers_y_dict = data_y 
        target_cols_list = expected_cols_for_model 
        missing_keys_in_scaler = [key for key in target_cols_list if key not in scalers_y_dict]
        if missing_keys_in_scaler:
            raise ValueError(f"ì´ì „ í˜•ì‹ '{scaler_y_path}' íŒŒì¼ì˜ ìŠ¤ì¼€ì¼ëŸ¬ì— ëˆ„ë½ëœ í‚¤: {missing_keys_in_scaler}")
    else:
        raise ValueError(f"'{scaler_y_path}' íŒŒì¼ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if model.output_dim != len(target_cols_list):
        st.error(f"ëª¨ë¸ ì¶œë ¥ ì°¨ì›({model.output_dim})ê³¼ íƒ€ê²Ÿ ì»¬ëŸ¼ ìˆ˜({len(target_cols_list)}) ë¶ˆì¼ì¹˜. íƒ€ê²Ÿ: {target_cols_list}")
        raise ValueError("Model output dimension and target columns mismatch.")
        
    return model, scaler_X, scalers_y_dict, target_cols_list

# --- Streamlit App Layout ---
st.set_page_config(layout="wide", page_title="Fatigue Life Predictor")
st.title('Fatigue Life Predictor (Îµ-N / Î³-N)')
st.write("Enter Monotonic Properties or Alloy Composition, Get Prediction.")

# --- Session State ì´ˆê¸°í™” ---
if 'prediction_triggered' not in st.session_state: st.session_state.prediction_triggered = False
if 'user_inputs' not in st.session_state: st.session_state.user_inputs = {}
if 'en_results' not in st.session_state: st.session_state.en_results = None
if 'shear_results' not in st.session_state: st.session_state.shear_results = None
if 'physics_params' not in st.session_state: st.session_state.physics_params = None
if 'input_mode' not in st.session_state: st.session_state.input_mode = "ë‹¨ì¡° ë¬¼ì„±ì¹˜ ì§ì ‘ ì…ë ¥"
if 'poisson_ratio_universal' not in st.session_state: st.session_state.poisson_ratio_universal = 0.3 # ê³µìš© í¬ì•„ì†¡ ë¹„ ì´ˆê¸°í™”

# ë¦¬ì†ŒìŠ¤ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆ)
try:
    model, scaler_X, scalers_y_dict, target_cols_list = load_resources()
except FileNotFoundError as e:
    st.error(f"í•„ìˆ˜ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}. ì•±ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
except ValueError as e:
    st.error(f"ë°ì´í„° íŒŒì¼ í˜•ì‹ ë˜ëŠ” ë‚´ìš© ì˜¤ë¥˜: {e}. ì•±ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
except Exception as e:
    st.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()


# Define elements for composition input globally for access
elements_for_input_definition = {
    'C': {'label': 'C (íƒ„ì†Œ)', 'default': 0.2, 'format': '%.3f', 'step': 0.001},
    'Mn': {'label': 'Mn (ë§ê°„)', 'default': 0.8, 'format': '%.3f', 'step': 0.01},
    'Si': {'label': 'Si (ê·œì†Œ)', 'default': 0.3, 'format': '%.3f', 'step': 0.01},
    'Cr': {'label': 'Cr (í¬ë¡¬)', 'default': 0.0, 'format': '%.3f', 'step': 0.01},
    'Mo': {'label': 'Mo (ëª°ë¦¬ë¸Œë´)', 'default': 0.0, 'format': '%.3f', 'step': 0.01},
    'Ni': {'label': 'Ni (ë‹ˆì¼ˆ)', 'default': 0.0, 'format': '%.3f', 'step': 0.01},
    'V': {'label': 'V (ë°”ë‚˜ë“)', 'default': 0.0, 'format': '%.3f', 'step': 0.001},
    'Nb': {'label': 'Nb (ë‹ˆì˜¤ë¸€)', 'default': 0.0, 'format': '%.4f', 'step': 0.0001},
    'Ti': {'label': 'Ti (í‹°íƒ€ëŠ„)', 'default': 0.0, 'format': '%.4f', 'step': 0.0001},
    'Al': {'label': 'Al (ì•Œë£¨ë¯¸ëŠ„)', 'default': 0.0, 'format': '%.3f', 'step': 0.001},
    'N': {'label': 'N (ì§ˆì†Œ)', 'default': 0.0, 'format': '%.4f', 'step': 0.0001},
    'Cu': {'label': 'Cu (êµ¬ë¦¬)', 'default': 0.0, 'format': '%.3f', 'step': 0.01},
    'P': {'label': 'P (ì¸)', 'default': 0.015, 'format': '%.4f', 'step': 0.001},
    'S': {'label': 'S (í™©)', 'default': 0.015, 'format': '%.4f', 'step': 0.001},
    'B': {'label': 'B (ë¶•ì†Œ)', 'default': 0.0, 'format': '%.5f', 'step': 0.00001}
}

# ì‚¬ì´ë“œë°”ì— ì…ë ¥ ì„¹ì…˜ ë°°ì¹˜
with st.sidebar:
    st.header("ì…ë ¥ ëª¨ë“œ ë° íŒŒë¼ë¯¸í„°")

    st.radio(
        "ì…ë ¥ ë°©ì‹ ì„ íƒ:",
        ("ë‹¨ì¡° ë¬¼ì„±ì¹˜ ì§ì ‘ ì…ë ¥", "í•©ê¸ˆ ì¡°ì„±ë¹„ ì…ë ¥ (wt%)"),
        key='input_mode',
        horizontal=True,
        on_change=lambda: setattr(st.session_state, 'prediction_triggered', False)
    )

    if st.session_state.input_mode == "ë‹¨ì¡° ë¬¼ì„±ì¹˜ ì§ì ‘ ì…ë ¥":
        st.subheader("ì¬ë£Œ íŠ¹ì„± (ì§ì ‘ ì…ë ¥)")
        e_mod_gpa_direct_input = st.number_input('íƒ„ì„± ê³„ìˆ˜ (E, GPa)', min_value=1.0, value=200.0, format='%.1f', help="GPa ë‹¨ìœ„. (ì˜ˆ: ê°•ì²  ~200 GPa)", key="e_mod_gpa_direct")
        ys_mpa_direct_input = st.number_input('í•­ë³µ ê°•ë„ (YS, MPa)', min_value=1.0, value=500.0, format='%.1f', key="ys_mpa_direct")
        ts_mpa_direct_input = st.number_input('ì¸ì¥ ê°•ë„ (UTS, MPa)', min_value=1.0, value=700.0, format='%.1f', key="ts_mpa_direct")
        hb_direct_input_val = st.number_input('ë¸Œë¦¬ë„¬ ê²½ë„ (HB)', min_value=0.0, value=200.0, format='%.1f', help="ë¬¼ë¦¬ ê¸°ë°˜ ê³„ì‚° ë° ëª¨ë¸ ì…ë ¥ìš©. 0 ì…ë ¥ ì‹œ TSë¡œë¶€í„° ì¶”ì •.", key="hb_direct")
        poisson_direct_input = st.number_input("í¬ì•„ì†¡ ë¹„ (Î½)", min_value=0.0, max_value=0.5, value=0.3, step=0.01, format='%.2f', help="ì „ë‹¨ ê³„ì‚°ì— ì‚¬ìš©.", key="poisson_direct")

        if hb_direct_input_val is not None and hb_direct_input_val <= 0:
             st.info("HB ê°’ì´ 0 ì´í•˜ë¡œ ì…ë ¥ë˜ì–´ ì¸ì¥ê°•ë„(TS)ë¡œë¶€í„° HBë¥¼ ì¶”ì •í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤ (ëª¨ë¸ ì…ë ¥ ë° ë¬¼ë¦¬ì‹ ê³„ì‚° ì‹œ).")

    elif st.session_state.input_mode == "í•©ê¸ˆ ì¡°ì„±ë¹„ ì…ë ¥ (wt%)":
        st.subheader("í•©ê¸ˆ ì¡°ì„± (wt%)")
        
        col1_comp, col2_comp = st.columns(2)
        element_keys_col1 = list(elements_for_input_definition.keys())[:8]
        
        for el_key, props in elements_for_input_definition.items():
            target_col = col1_comp if el_key in element_keys_col1 else col2_comp
            with target_col:
                st.number_input(
                    props['label'], min_value=0.0, value=props['default'], 
                    format=props['format'], step=props['step'], key=f"comp_{el_key}"
                )
        
        current_composition_sum = sum(st.session_state[f"comp_{el}"] for el in elements_for_input_definition if f"comp_{el}" in st.session_state)
        st.caption(f"ì…ë ¥ëœ ì¡°ì„±ì˜ í•©ê³„: {current_composition_sum:.3f} wt%. (FeëŠ” ì”ëŸ‰ìœ¼ë¡œ ê°„ì£¼)")

    if st.button("í”¼ë¡œ ê±°ë™ ì˜ˆì¸¡ ì‹¤í–‰", use_container_width=True, type="primary"):
        st.session_state.prediction_triggered = True
        st.session_state.en_results = None
        st.session_state.shear_results = None
        st.session_state.physics_params = None
        st.session_state.user_inputs = {}

        # Initialize common variables for prediction
        e_gpa_to_use, ys_mpa_to_use, ts_mpa_to_use, hb_to_use, nu_to_use = None, None, None, None, None
        input_mode_str = st.session_state.input_mode
        
        try:
            if st.session_state.input_mode == "ë‹¨ì¡° ë¬¼ì„±ì¹˜ ì§ì ‘ ì…ë ¥":
                e_gpa_to_use = st.session_state.e_mod_gpa_direct
                ys_mpa_to_use = st.session_state.ys_mpa_direct
                ts_mpa_to_use = st.session_state.ts_mpa_direct
                hb_to_use = st.session_state.hb_direct
                nu_to_use = st.session_state.poisson_direct
                
                if not validate_monotonic_inputs(e_gpa_to_use, ys_mpa_to_use, ts_mpa_to_use, hb_to_use, nu_to_use):
                    raise ValueError("ì§ì ‘ ì…ë ¥ëœ ì¬ë£Œ ë¬¼ì„±ì¹˜ ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨.")
                
                st.session_state.user_inputs = {
                    'E_gpa': e_gpa_to_use, 'YS_mpa': ys_mpa_to_use, 'TS_mpa': ts_mpa_to_use,
                    'HB': hb_to_use, 'nu': nu_to_use, 'Input_Mode': input_mode_str
                }

            elif st.session_state.input_mode == "í•©ê¸ˆ ì¡°ì„±ë¹„ ì…ë ¥ (wt%)":
                current_composition = {el: st.session_state[f"comp_{el}"] for el in elements_for_input_definition}
                
                if not validate_composition_inputs(current_composition):
                    raise ValueError("ì…ë ¥ëœ í•©ê¸ˆ ì¡°ì„± ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨.")

                # e_gpa_to_useëŠ” ì˜ˆì¸¡ê°’ì„ ì‚¬ìš©í•˜ê³ , nu_to_useëŠ” ê³µìš© ê°’ì„ ì‚¬ìš©
                predicted_props = ctp.calculate_monotonic_properties(current_composition)
                e_gpa_to_use = predicted_props.get('E_gpa') 
                ys_mpa_to_use = predicted_props.get('YS_mpa')
                ts_mpa_to_use = predicted_props.get('TS_mpa')
                hb_to_use = predicted_props.get('HB') # Can be None or NaN
                nu_to_use = st.session_state.poisson_ratio_universal # ê³µìš© í¬ì•„ì†¡ ë¹„ ì‚¬ìš©

                if not validate_monotonic_inputs(e_gpa_to_use, ys_mpa_to_use, ts_mpa_to_use, hb_to_use, nu_to_use):
                    raise ValueError("ì¡°ì„±ìœ¼ë¡œë¶€í„° ì˜ˆì¸¡/ì…ë ¥ëœ ë¬¼ì„±ì¹˜ ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨.")
                
                st.session_state.user_inputs = {
                    'E_gpa': e_gpa_to_use, 'YS_mpa': ys_mpa_to_use, 'TS_mpa': ts_mpa_to_use,
                    'HB': hb_to_use, 'nu': nu_to_use, 'Input_Mode': input_mode_str,
                    'Composition_Details': current_composition
                }
                st.sidebar.success("ì¡°ì„± ê¸°ë°˜ ë¬¼ì„±ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ. í”¼ë¡œ ê±°ë™ ë¶„ì„ ì§„í–‰.")

            # Common prediction logic using *_to_use variables
            e_mod_mpa_calc = e_gpa_to_use * 1000
            st.session_state.user_inputs['E_mpa'] = e_mod_mpa_calc # Add E_mpa to user_inputs

            # hb_to_pass handles None, NaN, or <=0 values for HB_val before model prediction
            hb_for_model = hb_to_use 
            if hb_to_use is None or np.isnan(hb_to_use) or hb_to_use <= 0:
                 hb_for_model = np.nan # predict_fatigue_curves_hybrid will estimate if TS is valid

            predicted_en_results = predict_fatigue_curves_hybrid(
                e_gpa_to_use, ys_mpa_to_use, ts_mpa_to_use, hb_for_model,
                model, scaler_X, scalers_y_dict, target_cols_list, device
            )
            st.session_state.en_results = predicted_en_results
            
            # Use hb_to_use for physics params (get_physics_params handles None/NaN/0 internally)
            spf_phys, epf_phys, phys_method_name = get_physics_params(
                hb_to_use, ts_mpa_to_use, e_mod_mpa_calc
            )
            st.session_state.physics_params = {
                'spf_MPa_phys': spf_phys, 'epf_phys': epf_phys, 'method_name': phys_method_name
            }

            st.session_state.shear_results = convert_to_shear_parameters(
                spf_prime=predicted_en_results['sigma_f_prime'],
                b_fatigue=predicted_en_results['b_fatigue'],
                epf_prime=predicted_en_results['epsilon_f_prime'],
                c_fatigue=predicted_en_results['c_fatigue'],
                E_gpa=e_gpa_to_use, TS_mpa=ts_mpa_to_use, nu=nu_to_use
            )

        except ValueError as ve: # Catches validation errors and others
            st.sidebar.error(f"ì˜¤ë¥˜: {ve}")
        except AttributeError as ae: # ctp module related
            st.sidebar.error(f"ì¡°ì„± ì˜ˆì¸¡ ëª¨ë“ˆ ì˜¤ë¥˜: {ae}. 'composition_to_properties.py'ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        except KeyError as ke: # ctp result dictionary key error
            st.sidebar.error(f"ì¡°ì„± ì˜ˆì¸¡ ê²°ê³¼ í‚¤ ì˜¤ë¥˜: {ke}. 'composition_to_properties.py' ë°˜í™˜ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        except Exception as e:
            st.sidebar.error(f"ì˜ˆì¸¡ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")


# --- Main Area for Results ---
if st.session_state.prediction_triggered and st.session_state.en_results:
    tab_titles = ["í”¼ë¡œ íŒŒë¼ë¯¸í„° ìš”ì•½", "ì¸ì¥ ê³¡ì„  (Ïµ-N)", "ì „ë‹¨ ê³¡ì„  (Î³-N)"]
    tabs = st.tabs(tab_titles)

    with tabs[0]: # Parameter Summary Tab
        st.subheader("í”¼ë¡œ íŒŒë¼ë¯¸í„° ìš”ì•½")
        en_p = st.session_state.en_results
        phys_p = st.session_state.physics_params
        shear_p = st.session_state.shear_results
        user_p = st.session_state.user_inputs

        st.write(f"**ì…ë ¥ ëª¨ë“œ:** {user_p.get('Input_Mode', 'N/A')}")
        if user_p.get('Input_Mode') == "í•©ê¸ˆ ì¡°ì„±ë¹„ ì…ë ¥ (wt%)":
            with st.expander("ì…ë ¥ëœ í•©ê¸ˆ ì¡°ì„± ìƒì„¸"):
                comp_details_df = pd.DataFrame(list(user_p.get('Composition_Details', {}).items()), columns=['Element', 'wt%'])
                st.dataframe(comp_details_df)
        
        st.markdown("#### AI ëª¨ë¸ ì˜ˆì¸¡ (ì¸ì¥)")
        col1, col2 = st.columns(2)
        with col1:
            st.metric(r"$\sigma_f'$ (í”¼ë¡œ ê°•ë„ ê³„ìˆ˜, Fatigue Strength Coeff.)", f"{en_p.get('sigma_f_prime', np.nan):.2f} MPa")
            st.metric(r"$b$ (í”¼ë¡œ ê°•ë„ ì§€ìˆ˜, Fatigue Strength Exponent)", f"{en_p.get('b_fatigue', np.nan):.4f}")
        with col2:
            st.metric(r"$\epsilon_f'$ (í”¼ë¡œ ì—°ì„± ê³„ìˆ˜, Fatigue Ductility Coeff.)", f"{en_p.get('epsilon_f_prime', np.nan):.4f}")
            st.metric(r"$c$ (í”¼ë¡œ ì—°ì„± ì§€ìˆ˜, Fatigue Ductility Exponent)", f"{en_p.get('c_fatigue', np.nan):.4f}")
        
        if phys_p and not (np.isnan(phys_p.get('spf_MPa_phys', np.nan)) and np.isnan(phys_p.get('epf_phys', np.nan))):
            st.markdown(f"#### ë¬¼ë¦¬ ê¸°ë°˜ ê²½í—˜ì‹ ({phys_p.get('method_name', 'N/A')})")
            col3, col4 = st.columns(2)
            with col3:
                st.metric(r"$\sigma_f'$ (ê³„ì‚°ê°’)", f"{phys_p.get('spf_MPa_phys', np.nan):.2f} MPa")
            with col4:
                st.metric(r"$\epsilon_f'$ (ê³„ì‚°ê°’)", f"{phys_p.get('epf_phys', np.nan):.4f}")

        if shear_p and not np.isnan(shear_p.get('tauf_MPa', np.nan)):
            st.markdown(f"#### ì „ë‹¨ ë³€í™˜ ê²°ê³¼ ({shear_p.get('conversion_method', 'N/A')})")
            col5, col6 = st.columns(2)
            with col5:
                st.metric(r"$\tau_f'$ (ì „ë‹¨ í”¼ë¡œ ê°•ë„ ê³„ìˆ˜, Shear Fatigue Strength Coeff.)", f"{shear_p.get('tauf_MPa', np.nan):.2f} MPa")
                st.metric(r"$\gamma_f'$ (ì „ë‹¨ í”¼ë¡œ ì—°ì„± ê³„ìˆ˜, Shear Fatigue Ductility Coeff.)", f"{shear_p.get('gammaf', np.nan):.4f}")
                st.metric("$G$ (ì „ë‹¨ íƒ„ì„± ê³„ìˆ˜, Shear Modulus)", f"{shear_p.get('G_mpa', np.nan):.0f} MPa")
            with col6: # b0 and c0 are same as b and c
                st.metric("$b_0$ (ì „ë‹¨ í”¼ë¡œ ê°•ë„ ì§€ìˆ˜, Shear Fatigue Strength Exponent)", f"{shear_p.get('b0', np.nan):.4f}")
                st.metric("$c_0$ (ì „ë‹¨ í”¼ë¡œ ì—°ì„± ì§€ìˆ˜, Shear Fatigue Ductility Exponent)", f"{shear_p.get('c0', np.nan):.4f}")
        
        st.markdown("---")
        st.markdown(r"**ì¸ì¥ Coffin-Manson:** $\frac{\Delta\epsilon}{2} = \frac{\sigma'_f}{E}\,(2N_f)^b + \epsilon'_f\,(2N_f)^c$")
        if shear_p and not np.isnan(shear_p.get('tauf_MPa', np.nan)):
             st.markdown(r"**ì „ë‹¨ Coffin-Manson:** $\frac{\Delta\gamma}{2} = \frac{\tau'_f}{G}\,(2N_f)^{b_0} + \gamma'_f\,(2N_f)^{c_0}$")
        
        # Consolidate all parameters for download
        all_params_list = [
            ("Input Mode", user_p.get('Input_Mode', 'N/A')),
            ("E (GPa, Input)", user_p.get('E_gpa', np.nan)),
            ("YS (MPa, Input/Predicted)", user_p.get('YS_mpa', np.nan)),
            ("TS (MPa, Input/Predicted)", user_p.get('TS_mpa', np.nan)),
            ("HB (Input/Predicted)", user_p.get('HB', np.nan)),
            ("HB (Model Input)", en_p.get('HB_processed_for_prediction', np.nan)),
            ("Î½ (Input)", user_p.get('nu', np.nan)),
            ("AI: Ïƒf' (MPa)", en_p.get('sigma_f_prime', np.nan)),
            ("AI: b", en_p.get('b_fatigue', np.nan)),
            ("AI: Îµf'", en_p.get('epsilon_f_prime', np.nan)),
            ("AI: c", en_p.get('c_fatigue', np.nan)),
        ]
        if phys_p:
            all_params_list.extend([
                (f"Physics ({phys_p.get('method_name', 'N/A')}): Ïƒf' (MPa)", phys_p.get('spf_MPa_phys', np.nan)),
                (f"Physics ({phys_p.get('method_name', 'N/A')}): Îµf'", phys_p.get('epf_phys', np.nan)),
            ])
        if shear_p:
            all_params_list.extend([
                (f"Shear ({shear_p.get('conversion_method', 'N/A')}): Ï„f' (MPa)", shear_p.get('tauf_MPa', np.nan)),
                (f"Shear ({shear_p.get('conversion_method', 'N/A')}): b0", shear_p.get('b0', np.nan)),
                (f"Shear ({shear_p.get('conversion_method', 'N/A')}): Î³f'", shear_p.get('gammaf', np.nan)),
                (f"Shear ({shear_p.get('conversion_method', 'N/A')}): c0", shear_p.get('c0', np.nan)),
                (f"Shear ({shear_p.get('conversion_method', 'N/A')}): G (MPa)", shear_p.get('G_mpa', np.nan)),
            ])
        
        df_all_params = pd.DataFrame(all_params_list, columns=['Parameter', 'Value'])
        # Format float values
        for col in df_all_params.columns:
            if df_all_params[col].dtype == 'object': # Check if column might contain floats
                try:
                    df_all_params[col] = pd.to_numeric(df_all_params[col], errors='ignore')
                except: pass # Ignore if conversion fails for mixed types like 'Parameter'
        
        float_cols = df_all_params.select_dtypes(include=np.number).columns
        format_dict = {col: lambda x: f"{x:.4f}" if isinstance(x, float) and not np.isnan(x) else x for col in float_cols}

        st.download_button(
            label="ëª¨ë“  ì˜ˆì¸¡/ê³„ì‚° íŒŒë¼ë¯¸í„° CSV ë‹¤ìš´ë¡œë“œ",
            data=df_all_params.to_csv(index=False, float_format='%.4f').encode('utf-8-sig'), # utf-8-sig for Excel
            file_name="predicted_fatigue_parameters.csv",
            mime='text/csv',
            use_container_width=True
        )

    with tabs[1]: # Tensile Curve Tab
        st.subheader("Ïµ-N (ì¸ì¥ ë³€í˜•ë¥ -ìˆ˜ëª…) ê³¡ì„ ")
        en_data = st.session_state.en_results
        fig_en, ax_en = plt.subplots(figsize=(10, 6))
        
        Nf_plot = en_data.get("Nf", np.array([])) * 2 # Plot against 2Nf (Reversals)
        total_strain = en_data.get("total_strain_amplitude")
        elastic_strain = en_data.get("elastic_strain_amplitude")
        plastic_strain = en_data.get("plastic_strain_amplitude")

        plot_valid = False
        if total_strain is not None and not np.all(np.isnan(total_strain)):
            ax_en.loglog(Nf_plot, total_strain, '-', label='Total Strain (Îµ_a,pred)', linewidth=2)
            if elastic_strain is not None: ax_en.loglog(Nf_plot, elastic_strain, '--', label='Elastic Strain (pred)', alpha=0.8)
            if plastic_strain is not None: ax_en.loglog(Nf_plot, plastic_strain, ':', label='Plastic Strain (pred)', alpha=0.8)
            plot_valid = True
            
        if plot_valid:
            ax_en.set_xlabel('Reversals to Failure (2Nf)')
            ax_en.set_ylabel('Strain Amplitude (Îµ_a)')
            ax_en.legend()
            ax_en.grid(True, which="both", ls="-", alpha=0.7)
            valid_strains = total_strain[~np.isnan(total_strain)] # Use original total_strain for limits
            if len(valid_strains) > 0:
                ax_en.set_ylim(bottom=max(1e-5, np.min(valid_strains[valid_strains > 0]) * 0.5), top=np.max(valid_strains) * 1.5)
            else:
                ax_en.set_ylim(bottom=1e-5)
            ax_en.set_title('Predicted E-N (Strain-Life) Curve')
        else:
            ax_en.text(0.5, 0.5, 'E-N Curve data not available or contains NaNs.', ha='center', va='center', transform=ax_en.transAxes)
            ax_en.set_title('Predicted E-N (Strain-Life) Curve (Data N/A)')
        
        st.pyplot(fig_en)

        df_en_curve = pd.DataFrame({
            'Reversals_2Nf': Nf_plot,
            'Total_Strain_Amplitude': total_strain,
            'Elastic_Strain_Amplitude': elastic_strain,
            'Plastic_Strain_Amplitude': plastic_strain,
            'Stress_Amplitude_MPa': en_data.get("stress_amplitude")
        })
        csv_en_curve = df_en_curve.to_csv(index=False, float_format='%.5e').encode('utf-8-sig')
        
        img_en_buf = io.BytesIO()
        fig_en.savefig(img_en_buf, format="png", dpi=300)
        img_en_buf.seek(0)

        dl_col1_en, dl_col2_en = st.columns(2)
        with dl_col1_en:
            st.download_button(label="E-N ê³¡ì„  ë°ì´í„° (CSV) ë‹¤ìš´ë¡œë“œ", data=csv_en_curve, file_name="en_curve_data.csv", mime="text/csv", use_container_width=True, disabled=not plot_valid)
        with dl_col2_en:
            st.download_button(label="E-N ê³¡ì„  ì´ë¯¸ì§€ (PNG) ë‹¤ìš´ë¡œë“œ", data=img_en_buf, file_name="en_curve_plot.png", mime="image/png", use_container_width=True, disabled=not plot_valid)

        with st.expander("E-N ê³¡ì„  ìˆ˜ì¹˜ ë°ì´í„° ë³´ê¸°"):
            if plot_valid and not df_en_curve.empty:
                st.dataframe(df_en_curve.style.format("{:.4e}"))
            else:
                st.write("í‘œì‹œí•  E-N ê³¡ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tabs[2]: # Shear Curve Tab
        st.subheader("Î³-N (ì „ë‹¨ ë³€í˜•ë¥ -ìˆ˜ëª…) ê³¡ì„ ")
        shear_results_gn = st.session_state.shear_results
        en_base_data_gn = st.session_state.en_results # For Nf
        
        fig_gn, ax_gn = plt.subplots(figsize=(10, 6))
        plot_valid_gn = False
        df_gn_curve_plot = pd.DataFrame() # Initialize

        if shear_results_gn and en_base_data_gn:
            Nf_gn_plot = en_base_data_gn.get("Nf", np.array([])) * 2 # Reversals (2Nf)

            tauf_prime = shear_results_gn.get('tauf_MPa')
            gammaf_prime = shear_results_gn.get('gammaf')
            b0 = shear_results_gn.get('b0')
            c0 = shear_results_gn.get('c0')
            G_mpa = shear_results_gn.get('G_mpa')

            if all(val is not None and not np.isnan(val) for val in [tauf_prime, gammaf_prime, b0, c0, G_mpa]) and G_mpa > 0 and len(Nf_gn_plot) > 0:
                el_shear_strain = (tauf_prime / G_mpa) * (Nf_gn_plot / 2)**b0 # Nf_gn_plot is 2Nf, formula uses Nf or 2Nf depending on b0 def. Assuming b0 is for 2Nf.
                pl_shear_strain = gammaf_prime * (Nf_gn_plot / 2)**c0         # Let's assume b0, c0 are for Nf (cycles)
                                                                              # Original code used reversals_gn_plot ** b0_gn which was Nf.
                                                                              # The Coffin-Manson is usually (2Nf)^b or (Nf)^b.
                                                                              # The plot X-axis is 2Nf.
                                                                              # If b,c are for 2Nf: (tau_f'/G)*(2Nf)^b + gamma_f'*(2Nf)^c
                                                                              # If b,c are for Nf: (tau_f'/G)*(Nf)^b + gamma_f'*(Nf)^c
                                                                              # The E-N curve used (2*Nf)**b. So shear should be consistent.
                
                # Assuming b0, c0 are exponents for 2Nf (reversals)
                elastic_shear_strain_gn = (tauf_prime / G_mpa) * (Nf_gn_plot)**b0
                plastic_shear_strain_gn = gammaf_prime * (Nf_gn_plot)**c0
                total_shear_strain_gn = elastic_shear_strain_gn + plastic_shear_strain_gn
                
                ax_gn.loglog(Nf_gn_plot, total_shear_strain_gn, '-', label='Total Shear Strain (Î³_a,pred)', linewidth=2)
                ax_gn.loglog(Nf_gn_plot, elastic_shear_strain_gn, '--', label='Elastic Shear Strain (pred)', alpha=0.8)
                ax_gn.loglog(Nf_gn_plot, plastic_shear_strain_gn, ':', label='Plastic Shear Strain (pred)', alpha=0.8)
                plot_valid_gn = True

                df_gn_curve_plot = pd.DataFrame({
                    'Reversals_2Nf': Nf_gn_plot,
                    'Total_Shear_Strain_Amplitude': total_shear_strain_gn,
                    'Elastic_Shear_Strain_Amplitude': elastic_shear_strain_gn,
                    'Plastic_Shear_Strain_Amplitude': plastic_shear_strain_gn
                })
        
        if plot_valid_gn:
            ax_gn.set_xlabel('Reversals to Failure (2Nf)')
            ax_gn.set_ylabel('Shear Strain Amplitude (Î³_a)')
            ax_gn.legend()
            ax_gn.grid(True, which="both", ls="-", alpha=0.7)
            valid_strains_gn = df_gn_curve_plot['Total_Shear_Strain_Amplitude'].dropna()
            if not valid_strains_gn.empty:
                 ax_gn.set_ylim(bottom=max(1e-5, valid_strains_gn[valid_strains_gn > 0].min() * 0.5), top=valid_strains_gn.max() * 1.5)
            else:
                ax_gn.set_ylim(bottom=1e-5)
            ax_gn.set_title('Predicted Î³-N (Shear Strain-Life) Curve')
            st.caption(f"ì „ë‹¨ ë³€í™˜ ë°©ë²•: {shear_results_gn.get('conversion_method', 'N/A')}")
        else:
            ax_gn.text(0.5, 0.5, 'Î³-N Curve data not available or parameters invalid.', ha='center', va='center', transform=ax_gn.transAxes)
            ax_gn.set_title('Predicted Î³-N (Shear Strain-Life) Curve (Data N/A)')
            if not shear_results_gn or np.isnan(shear_results_gn.get('G_mpa', np.nan)) or shear_results_gn.get('G_mpa', 0) <=0 :
                 st.warning("ì „ë‹¨ í”¼ë¡œ íŒŒë¼ë¯¸í„° ê³„ì‚°ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ì „ë‹¨ íƒ„ì„± ê³„ìˆ˜(G)ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ Î³-N ê³¡ì„ ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        st.pyplot(fig_gn)

        csv_gn_curve = df_gn_curve_plot.to_csv(index=False, float_format='%.5e').encode('utf-8-sig')
        img_gn_buf = io.BytesIO()
        fig_gn.savefig(img_gn_buf, format="png", dpi=300)
        img_gn_buf.seek(0)

        dl_gn_col1, dl_gn_col2 = st.columns(2)
        with dl_gn_col1:
            st.download_button(label="Î³-N ê³¡ì„  ë°ì´í„° (CSV) ë‹¤ìš´ë¡œë“œ", data=csv_gn_curve, file_name="gamma_n_curve_data.csv", mime="text/csv", use_container_width=True, disabled=not plot_valid_gn)
        with dl_gn_col2:
            st.download_button(label="Î³-N ê³¡ì„  ì´ë¯¸ì§€ (PNG) ë‹¤ìš´ë¡œë“œ", data=img_gn_buf, file_name="gamma_n_curve_plot.png", mime="image/png", use_container_width=True, disabled=not plot_valid_gn)

        with st.expander("Î³-N ê³¡ì„  ìˆ˜ì¹˜ ë°ì´í„° ë³´ê¸°"):
            if plot_valid_gn and not df_gn_curve_plot.empty:
                 st.dataframe(df_gn_curve_plot.style.format("{:.4e}"))
            else:
                st.write("í‘œì‹œí•  Î³-N ê³¡ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info('ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥ ëª¨ë“œë¥¼ ì„ íƒí•˜ê³ , í•„ìš”í•œ ê°’ì„ ì…ë ¥í•œ í›„ "í”¼ë¡œ ê±°ë™ ì˜ˆì¸¡ ì‹¤í–‰" ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.')

st.divider()
st.markdown(
    """
    <div style="text-align: center; color: grey; font-size: 0.8em;">
        Â© 2024 YeoJoon Yoon. All Rights Reserved.<br>
        Contact: <a href="mailto:goat@sogang.ac.kr">goat@sogang.ac.kr</a>
    </div>
    """,
    unsafe_allow_html=True
)

# streamlit run FatiguePredictor0529.py